{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80ef63-07ec-425a-bd53-e1f59efc4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "class HospitalEnv(gym.Env):\n",
    "    def __init__(self, max_steps=30):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_steps = max_steps  # maximum steps per episode\n",
    "\n",
    "        # Observation space: 10 features\n",
    "        self.observation_space = spaces.Box(low=0, high=200, shape=(10,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)  # RED=0, YELLOW=1, GREEN=2\n",
    "\n",
    "        # Doctors\n",
    "        self.num_doctors = 3\n",
    "        self.doctor_timers = np.zeros(self.num_doctors)\n",
    "\n",
    "        # Queues\n",
    "        self.red_queue = []\n",
    "        self.yellow_queue = []\n",
    "        self.green_queue = []\n",
    "\n",
    "        # Arrival tracking\n",
    "        self.arrival_caps = {\"red\": 3, \"yellow\": 5, \"green\": 5}\n",
    "        self.arrivals_done = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "\n",
    "        # Service times (lognormal)\n",
    "        self.red_mu, self.red_sigma = self._lognormal(20, 6)\n",
    "        self.yellow_mu, self.yellow_sigma = self._lognormal(12, 4)\n",
    "        self.green_mu, self.green_sigma = self._lognormal(8, 2)\n",
    "\n",
    "        # Step counter\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Track last 5 actions for GREEN reward\n",
    "        self.last_5_actions = []\n",
    "\n",
    "        # Track last served wait times per category\n",
    "        self.last_served_wait_times = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Lognormal conversion\n",
    "    # -------------------------------------------\n",
    "    def _lognormal(self, mean, std):\n",
    "        variance = std ** 2\n",
    "        mu = np.log(mean**2 / np.sqrt(variance + mean**2))\n",
    "        sigma = np.sqrt(np.log(1 + variance / (mean**2)))\n",
    "        return mu, sigma\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Reset environment\n",
    "    # -------------------------------------------\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.red_queue = []\n",
    "        self.yellow_queue = []\n",
    "        self.green_queue = []\n",
    "        self.arrivals_done = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "        self.doctor_timers[:] = 0\n",
    "        self.current_step = 0\n",
    "        self.last_5_actions = []\n",
    "        self.last_served_wait_times = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "        obs = self._get_obs()\n",
    "        return obs, {}\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Observation\n",
    "    # -------------------------------------------\n",
    "    def _get_obs(self):\n",
    "        return np.array([\n",
    "            np.sum(self.doctor_timers == 0),  # free doctors\n",
    "            max(self.red_queue) if self.red_queue else 0,\n",
    "            max(self.yellow_queue) if self.yellow_queue else 0,\n",
    "            max(self.green_queue) if self.green_queue else 0,\n",
    "            len(self.red_queue),\n",
    "            len(self.yellow_queue),\n",
    "            len(self.green_queue),\n",
    "            self.doctor_timers[0],\n",
    "            self.doctor_timers[1],\n",
    "            self.doctor_timers[2],\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Sample service time\n",
    "    # -------------------------------------------\n",
    "    def _sample_service(self, action):\n",
    "        if action == 0:\n",
    "            return np.random.lognormal(self.red_mu, self.red_sigma)\n",
    "        elif action == 1:\n",
    "            return np.random.lognormal(self.yellow_mu, self.yellow_sigma)\n",
    "        else:\n",
    "            return np.random.lognormal(self.green_mu, self.green_sigma)\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Add new arrivals\n",
    "    # -------------------------------------------\n",
    "    def _add_new_arrivals(self):\n",
    "        new_red = np.random.poisson(lam=1)\n",
    "        new_yellow = np.random.poisson(lam=3)\n",
    "        new_green = np.random.poisson(lam=3)\n",
    "\n",
    "        self.red_queue.extend([0] * new_red)\n",
    "        self.yellow_queue.extend([0] * new_yellow)\n",
    "        self.green_queue.extend([0] * new_green)\n",
    "\n",
    "        # Increase waiting time of all existing patients\n",
    "        self.red_queue = [w + 1 for w in self.red_queue]\n",
    "        self.yellow_queue = [w + 1 for w in self.yellow_queue]\n",
    "        self.green_queue = [w + 1 for w in self.green_queue]\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Step function\n",
    "    # -------------------------------------------\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Wait until at least one doctor is free\n",
    "        free_doctors = np.where(self.doctor_timers == 0)[0]\n",
    "        if len(free_doctors) == 0:\n",
    "            min_timer = min([t for t in self.doctor_timers if t > 0])\n",
    "            self.doctor_timers = np.maximum(0, self.doctor_timers - min_timer)\n",
    "            free_doctors = np.where(self.doctor_timers == 0)[0]\n",
    "\n",
    "        doctor = free_doctors[0]\n",
    "\n",
    "        # Map action to queue\n",
    "        queue_map = {0: (\"red\", self.red_queue),\n",
    "                     1: (\"yellow\", self.yellow_queue),\n",
    "                     2: (\"green\", self.green_queue)}\n",
    "        cat_name, queue = queue_map[action]\n",
    "\n",
    "        # If queue empty → 0 reward\n",
    "        if len(queue) == 0:\n",
    "            reward = 0\n",
    "        else:\n",
    "            wait_time = queue.pop(0)\n",
    "            dt = self._sample_service(action)\n",
    "            self.doctor_timers[doctor] = dt\n",
    "\n",
    "            # Advance other doctors\n",
    "            for i in range(self.num_doctors):\n",
    "                if i != doctor:\n",
    "                    self.doctor_timers[i] = max(0, self.doctor_timers[i] - dt)\n",
    "\n",
    "            # Reward calculation\n",
    "            reward_map = {\"red\": 25, \"yellow\": 15, \"green\": 5}\n",
    "            reward = reward_map[cat_name] + 1\n",
    "\n",
    "            threshold_times = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "            if wait_time <= threshold_times[cat_name]:\n",
    "                reward += 5\n",
    "\n",
    "            # --- Save last served wait time for this category ---\n",
    "            self.last_served_wait_times[cat_name] = wait_time\n",
    "\n",
    "        # GREEN patient reward for recent service (fairness)\n",
    "        self.last_5_actions.append(action)\n",
    "        if len(self.last_5_actions) > 5:\n",
    "            self.last_5_actions.pop(0)\n",
    "        if 2 in self.last_5_actions:\n",
    "            reward += 8\n",
    "\n",
    "        \n",
    "\n",
    "        # Add new arrivals\n",
    "        self._add_new_arrivals()\n",
    "\n",
    "        # Truncated if max steps reached\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "\n",
    "        return self._get_obs(), reward, False, truncated, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a591a19a-57d4-4f32-9ed3-f2ce6e84f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "class HospitalEnv(gym.Env):\n",
    "    def __init__(self, max_steps=30):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_steps = max_steps  # maximum steps per episode\n",
    "\n",
    "        # Observation space: 10 features\n",
    "        self.observation_space = spaces.Box(low=0, high=200, shape=(10,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)  # RED=0, YELLOW=1, GREEN=2\n",
    "\n",
    "        # Doctors\n",
    "        self.num_doctors = 3\n",
    "        self.doctor_timers = np.zeros(self.num_doctors)\n",
    "\n",
    "        # Queues\n",
    "        self.red_queue = []\n",
    "        self.yellow_queue = []\n",
    "        self.green_queue = []\n",
    "\n",
    "        # Arrival tracking\n",
    "        self.arrival_caps = {\"red\": 3, \"yellow\": 5, \"green\": 5}\n",
    "        self.arrivals_done = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "\n",
    "        # Service times (lognormal)\n",
    "        self.red_mu, self.red_sigma = self._lognormal(20, 6)\n",
    "        self.yellow_mu, self.yellow_sigma = self._lognormal(12, 4)\n",
    "        self.green_mu, self.green_sigma = self._lognormal(8, 2)\n",
    "\n",
    "        # Step counter\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Track last 5 actions for GREEN reward\n",
    "        self.last_5_actions = []\n",
    "\n",
    "        # Track last served wait times per category\n",
    "        self.last_served_wait_times = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Lognormal conversion\n",
    "    # -------------------------------------------\n",
    "    def _lognormal(self, mean, std):\n",
    "        variance = std ** 2\n",
    "        mu = np.log(mean**2 / np.sqrt(variance + mean**2))\n",
    "        sigma = np.sqrt(np.log(1 + variance / (mean**2)))\n",
    "        return mu, sigma\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Reset environment\n",
    "    # -------------------------------------------\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.red_queue = []\n",
    "        self.yellow_queue = []\n",
    "        self.green_queue = []\n",
    "        self.arrivals_done = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "        self.doctor_timers[:] = 0\n",
    "        self.current_step = 0\n",
    "        self.last_5_actions = []\n",
    "        self.last_served_wait_times = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "        obs = self._get_obs()\n",
    "        return obs, {}\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Observation\n",
    "    # -------------------------------------------\n",
    "    def _get_obs(self):\n",
    "        return np.array([\n",
    "            np.sum(self.doctor_timers == 0),  # free doctors\n",
    "            max(self.red_queue) if self.red_queue else 0,\n",
    "            max(self.yellow_queue) if self.yellow_queue else 0,\n",
    "            max(self.green_queue) if self.green_queue else 0,\n",
    "            len(self.red_queue),\n",
    "            len(self.yellow_queue),\n",
    "            len(self.green_queue),\n",
    "            self.doctor_timers[0],\n",
    "            self.doctor_timers[1],\n",
    "            self.doctor_timers[2],\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Sample service time\n",
    "    # -------------------------------------------\n",
    "    def _sample_service(self, action):\n",
    "        if action == 0:\n",
    "            return np.random.lognormal(self.red_mu, self.red_sigma)\n",
    "        elif action == 1:\n",
    "            return np.random.lognormal(self.yellow_mu, self.yellow_sigma)\n",
    "        else:\n",
    "            return np.random.lognormal(self.green_mu, self.green_sigma)\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Add new arrivals\n",
    "    # -------------------------------------------\n",
    "    def _add_new_arrivals(self):\n",
    "        new_red = np.random.poisson(lam=1)\n",
    "        new_yellow = np.random.poisson(lam=3)\n",
    "        new_green = np.random.poisson(lam=3)\n",
    "\n",
    "        self.red_queue.extend([0] * new_red)\n",
    "        self.yellow_queue.extend([0] * new_yellow)\n",
    "        self.green_queue.extend([0] * new_green)\n",
    "\n",
    "        # Increase waiting time of all existing patients\n",
    "        self.red_queue = [w + 1 for w in self.red_queue]\n",
    "        self.yellow_queue = [w + 1 for w in self.yellow_queue]\n",
    "        self.green_queue = [w + 1 for w in self.green_queue]\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Step function\n",
    "    # -------------------------------------------\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Wait until at least one doctor is free\n",
    "        free_doctors = np.where(self.doctor_timers == 0)[0]\n",
    "        if len(free_doctors) == 0:\n",
    "            min_timer = min([t for t in self.doctor_timers if t > 0])\n",
    "            self.doctor_timers = np.maximum(0, self.doctor_timers - min_timer)\n",
    "            free_doctors = np.where(self.doctor_timers == 0)[0]\n",
    "\n",
    "        doctor = free_doctors[0]\n",
    "\n",
    "        # Map action to queue\n",
    "        queue_map = {0: (\"red\", self.red_queue),\n",
    "                     1: (\"yellow\", self.yellow_queue),\n",
    "                     2: (\"green\", self.green_queue)}\n",
    "        cat_name, queue = queue_map[action]\n",
    "\n",
    "        # If queue empty → 0 reward\n",
    "        if len(queue) == 0:\n",
    "            reward = 0\n",
    "        else:\n",
    "            wait_time = queue.pop(0)\n",
    "            dt = self._sample_service(action)\n",
    "            self.doctor_timers[doctor] = dt\n",
    "\n",
    "            # Advance other doctors\n",
    "            for i in range(self.num_doctors):\n",
    "                if i != doctor:\n",
    "                    self.doctor_timers[i] = max(0, self.doctor_timers[i] - dt)\n",
    "\n",
    "            # Reward calculation\n",
    "            reward_map = {\"red\": 25, \"yellow\": 15, \"green\": 5}\n",
    "            reward = reward_map[cat_name] + 1\n",
    "\n",
    "            threshold_times = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "            if wait_time <= threshold_times[cat_name]:\n",
    "                reward += 5\n",
    "\n",
    "            # --- Save last served wait time for this category ---\n",
    "            self.last_served_wait_times[cat_name] = wait_time\n",
    "\n",
    "        # GREEN patient reward for recent service (fairness)\n",
    "        self.last_5_actions.append(action)\n",
    "        if len(self.last_5_actions) > 5:\n",
    "            self.last_5_actions.pop(0)\n",
    "        if 2 in self.last_5_actions:\n",
    "            reward += 2\n",
    "\n",
    "        \n",
    "\n",
    "        # Add new arrivals\n",
    "        self._add_new_arrivals()\n",
    "\n",
    "        # Truncated if max steps reached\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "\n",
    "        return self._get_obs(), reward, False, truncated, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b944c5-3178-4dd9-bfa0-3ac4c647aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1740     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 120      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 47.6     |\n",
      "|    n_updates        | 4        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 765      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 240      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 38.2     |\n",
      "|    n_updates        | 34       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.51e+03 |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 648      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 360      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.5     |\n",
      "|    n_updates        | 64       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 607      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 480      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.4     |\n",
      "|    n_updates        | 94       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.51e+03 |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 604      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 600      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.7     |\n",
      "|    n_updates        | 124      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.51e+03 |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 720      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.5     |\n",
      "|    n_updates        | 154      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 570      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 840      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 15.3     |\n",
      "|    n_updates        | 184      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 557      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 960      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 14.3     |\n",
      "|    n_updates        | 214      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1080     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 244      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.48e+03 |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 536      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26       |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 531      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1320     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 15.4     |\n",
      "|    n_updates        | 304      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.48e+03 |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 523      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1440     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20       |\n",
      "|    n_updates        | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.49e+03 |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 518      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 1560     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.8     |\n",
      "|    n_updates        | 364      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.5e+03  |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 513      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 1680     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 15.5     |\n",
      "|    n_updates        | 394      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.5e+03  |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 509      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 1800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 15.8     |\n",
      "|    n_updates        | 424      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.51e+03 |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 506      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 1920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.3     |\n",
      "|    n_updates        | 454      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 503      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2040     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 48.5     |\n",
      "|    n_updates        | 484      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 500      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2160     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.8     |\n",
      "|    n_updates        | 514      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 496      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2280     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.5     |\n",
      "|    n_updates        | 544      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 492      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.6     |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 489      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2520     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.7     |\n",
      "|    n_updates        | 604      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.53e+03 |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 486      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2640     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.4     |\n",
      "|    n_updates        | 634      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.52e+03 |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 485      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2760     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.1     |\n",
      "|    n_updates        | 664      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.53e+03 |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 482      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 2880     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.3     |\n",
      "|    n_updates        | 694      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 479      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.7     |\n",
      "|    n_updates        | 724      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 477      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 3120     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 754      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 3240     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.7     |\n",
      "|    n_updates        | 784      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.55e+03 |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 473      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 3360     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.8     |\n",
      "|    n_updates        | 814      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.54e+03 |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 470      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 3480     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.2     |\n",
      "|    n_updates        | 844      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.55e+03 |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 469      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.8     |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.55e+03 |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 466      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 3720     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.3     |\n",
      "|    n_updates        | 904      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.56e+03 |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 465      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 3840     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.5     |\n",
      "|    n_updates        | 934      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.56e+03 |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 461      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 3960     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.8     |\n",
      "|    n_updates        | 964      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.57e+03 |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 4080     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 38.1     |\n",
      "|    n_updates        | 994      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.244    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 456      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 4200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.2     |\n",
      "|    n_updates        | 1024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 455      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 4320     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 1054     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 453      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 4440     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.8     |\n",
      "|    n_updates        | 1084     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 4560     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26       |\n",
      "|    n_updates        | 1114     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.158    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 4680     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.9     |\n",
      "|    n_updates        | 1144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.2     |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 4920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.7     |\n",
      "|    n_updates        | 1204     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 5040     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 45.9     |\n",
      "|    n_updates        | 1234     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 5160     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.7     |\n",
      "|    n_updates        | 1264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 438      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 5280     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.2     |\n",
      "|    n_updates        | 1294     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 437      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 5400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.1     |\n",
      "|    n_updates        | 1324     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 5520     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 41.9     |\n",
      "|    n_updates        | 1354     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 5640     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.2     |\n",
      "|    n_updates        | 1384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 5760     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.7     |\n",
      "|    n_updates        | 1414     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 5880     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 1444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 6120     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 42       |\n",
      "|    n_updates        | 1504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 6240     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.3     |\n",
      "|    n_updates        | 1534     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 6360     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.6     |\n",
      "|    n_updates        | 1564     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 6480     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.1     |\n",
      "|    n_updates        | 1594     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 6600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 1624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 6720     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 38.8     |\n",
      "|    n_updates        | 1654     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 6840     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30       |\n",
      "|    n_updates        | 1684     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 6960     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 38.1     |\n",
      "|    n_updates        | 1714     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 7080     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 46.7     |\n",
      "|    n_updates        | 1744     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.5     |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 7320     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 41.8     |\n",
      "|    n_updates        | 1804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 7440     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 42.6     |\n",
      "|    n_updates        | 1834     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 7560     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 43.8     |\n",
      "|    n_updates        | 1864     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 7680     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 1894     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 7800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.9     |\n",
      "|    n_updates        | 1924     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 7920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.1     |\n",
      "|    n_updates        | 1954     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 8040     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 39.2     |\n",
      "|    n_updates        | 1984     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 8160     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.2     |\n",
      "|    n_updates        | 2014     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 8280     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35       |\n",
      "|    n_updates        | 2044     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.1     |\n",
      "|    n_updates        | 2074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 8520     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 2104     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 8640     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 2134     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 8760     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.7     |\n",
      "|    n_updates        | 2164     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 8880     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 2194     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 2224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 9120     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 38.1     |\n",
      "|    n_updates        | 2254     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 9240     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 2284     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 9360     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 42.4     |\n",
      "|    n_updates        | 2314     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 9480     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.3     |\n",
      "|    n_updates        | 2344     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.1     |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 9720     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.4     |\n",
      "|    n_updates        | 2404     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 9840     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 2434     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 9960     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 2464     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 10080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 39.4     |\n",
      "|    n_updates        | 2494     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 10200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.8     |\n",
      "|    n_updates        | 2524     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 10320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.3     |\n",
      "|    n_updates        | 2554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 10440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.5     |\n",
      "|    n_updates        | 2584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 10560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.6     |\n",
      "|    n_updates        | 2614     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 10680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 2644     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 10800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.8     |\n",
      "|    n_updates        | 2674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 10920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.2     |\n",
      "|    n_updates        | 2704     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 11040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.7     |\n",
      "|    n_updates        | 2734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 11160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.7     |\n",
      "|    n_updates        | 2764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 11280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 2794     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 11400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 2824     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 11520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.3     |\n",
      "|    n_updates        | 2854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 11640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28       |\n",
      "|    n_updates        | 2884     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 11760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 2914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 11880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.5     |\n",
      "|    n_updates        | 2944     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.3     |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 12120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 41.4     |\n",
      "|    n_updates        | 3004     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 12240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 3034     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 12360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.3     |\n",
      "|    n_updates        | 3064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 12480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 3094     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 12600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 41       |\n",
      "|    n_updates        | 3124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 12720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 40.7     |\n",
      "|    n_updates        | 3154     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 12840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.6     |\n",
      "|    n_updates        | 3184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.58e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 12960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 3214     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 13080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.4     |\n",
      "|    n_updates        | 3244     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 13200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 3274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 13320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.8     |\n",
      "|    n_updates        | 3304     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 13440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 3334     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.59e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 13560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.9     |\n",
      "|    n_updates        | 3364     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 13680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.6     |\n",
      "|    n_updates        | 3394     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 13800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.2     |\n",
      "|    n_updates        | 3424     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 13920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35       |\n",
      "|    n_updates        | 3454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 14040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.2     |\n",
      "|    n_updates        | 3484     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 14160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 3514     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 14280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 3544     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 14520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.3     |\n",
      "|    n_updates        | 3604     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 14640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 38.1     |\n",
      "|    n_updates        | 3634     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 14760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.9     |\n",
      "|    n_updates        | 3664     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.6e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 14880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 3694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.9     |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 15120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 3754     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 15240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.1     |\n",
      "|    n_updates        | 3784     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 15360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 41.7     |\n",
      "|    n_updates        | 3814     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 15480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 3844     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 15600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 15720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.1     |\n",
      "|    n_updates        | 3904     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 15840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 42.1     |\n",
      "|    n_updates        | 3934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 15960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.8     |\n",
      "|    n_updates        | 3964     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 16080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.4     |\n",
      "|    n_updates        | 3994     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 16200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.9     |\n",
      "|    n_updates        | 4024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 16320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.3     |\n",
      "|    n_updates        | 4054     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 16440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 39.4     |\n",
      "|    n_updates        | 4084     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 16560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 40.7     |\n",
      "|    n_updates        | 4114     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 16680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.4     |\n",
      "|    n_updates        | 4144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.7     |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 16920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 4204     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 17040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.5     |\n",
      "|    n_updates        | 4234     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 17160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.3     |\n",
      "|    n_updates        | 4264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 17280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33       |\n",
      "|    n_updates        | 4294     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 17400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.7     |\n",
      "|    n_updates        | 4324     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 17520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 39.2     |\n",
      "|    n_updates        | 4354     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 17640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.8     |\n",
      "|    n_updates        | 4384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 17760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.2     |\n",
      "|    n_updates        | 4414     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 17880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37       |\n",
      "|    n_updates        | 4444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 18120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 4504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 18240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.8     |\n",
      "|    n_updates        | 4534     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 18360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.9     |\n",
      "|    n_updates        | 4564     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 18480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 4594     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 18600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.8     |\n",
      "|    n_updates        | 4624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 18720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 4654     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 18840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.7     |\n",
      "|    n_updates        | 4684     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 18960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.4     |\n",
      "|    n_updates        | 4714     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 19080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.7     |\n",
      "|    n_updates        | 4744     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.2     |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 19320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 4804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 19440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.8     |\n",
      "|    n_updates        | 4834     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 19560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.1     |\n",
      "|    n_updates        | 4864     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 19680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.1     |\n",
      "|    n_updates        | 4894     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 19800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 4924     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 19920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.8     |\n",
      "|    n_updates        | 4954     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 20040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 4984     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 20160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 5014     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 20280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.1     |\n",
      "|    n_updates        | 5044     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 20400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 5074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 20520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 39.6     |\n",
      "|    n_updates        | 5104     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 20640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 37.1     |\n",
      "|    n_updates        | 5134     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 20760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.3     |\n",
      "|    n_updates        | 5164     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 20880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 5194     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 21000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.8     |\n",
      "|    n_updates        | 5224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 21120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.8     |\n",
      "|    n_updates        | 5254     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 21240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.5     |\n",
      "|    n_updates        | 5284     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 21360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 5314     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 21480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 5344     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 21720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 5404     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 21840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.2     |\n",
      "|    n_updates        | 5434     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 21960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.8     |\n",
      "|    n_updates        | 5464     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 22080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 41.8     |\n",
      "|    n_updates        | 5494     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 22200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.1     |\n",
      "|    n_updates        | 5524     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 22320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.1     |\n",
      "|    n_updates        | 5554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 22440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.2     |\n",
      "|    n_updates        | 5584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 22560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.7     |\n",
      "|    n_updates        | 5614     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 22680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.8     |\n",
      "|    n_updates        | 5644     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 22800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.9     |\n",
      "|    n_updates        | 5674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 22920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.7     |\n",
      "|    n_updates        | 5704     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 23040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.4     |\n",
      "|    n_updates        | 5734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 23160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 5764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 23280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 5794     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 23400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 5824     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 23520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.9     |\n",
      "|    n_updates        | 5854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 23640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 5884     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 23760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.3     |\n",
      "|    n_updates        | 5914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 23880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.3     |\n",
      "|    n_updates        | 5944     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.2     |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 24120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 39.7     |\n",
      "|    n_updates        | 6004     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 24240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.5     |\n",
      "|    n_updates        | 6034     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 24360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.5     |\n",
      "|    n_updates        | 6064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 24480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.8     |\n",
      "|    n_updates        | 6094     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 24600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 6124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 24720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 40.5     |\n",
      "|    n_updates        | 6154     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 24840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.6     |\n",
      "|    n_updates        | 6184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 24960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 6214     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 25080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.6     |\n",
      "|    n_updates        | 6244     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 25200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.6     |\n",
      "|    n_updates        | 6274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 25320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 6304     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 25440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.2     |\n",
      "|    n_updates        | 6334     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 25560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 36.6     |\n",
      "|    n_updates        | 6364     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 25680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.5     |\n",
      "|    n_updates        | 6394     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 25800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.8     |\n",
      "|    n_updates        | 6424     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 25920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.1     |\n",
      "|    n_updates        | 6454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 26040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.8     |\n",
      "|    n_updates        | 6484     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 26160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 6514     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 26280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.4     |\n",
      "|    n_updates        | 6544     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.4     |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 26520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.3     |\n",
      "|    n_updates        | 6604     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 26640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.7     |\n",
      "|    n_updates        | 6634     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 26760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.7     |\n",
      "|    n_updates        | 6664     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 26880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.5     |\n",
      "|    n_updates        | 6694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 27000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29       |\n",
      "|    n_updates        | 6724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 27120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 6754     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 27240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28       |\n",
      "|    n_updates        | 6784     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 27360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.6     |\n",
      "|    n_updates        | 6814     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 27480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 6844     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 27600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.5     |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 27720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.4     |\n",
      "|    n_updates        | 6904     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 27840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.8     |\n",
      "|    n_updates        | 6934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 27960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.2     |\n",
      "|    n_updates        | 6964     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 28080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.9     |\n",
      "|    n_updates        | 6994     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 28200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 7024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 28320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.9     |\n",
      "|    n_updates        | 7054     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 28440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.1     |\n",
      "|    n_updates        | 7084     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 28560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.8     |\n",
      "|    n_updates        | 7114     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 28680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.4     |\n",
      "|    n_updates        | 7144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 28920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 7204     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 29040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.6     |\n",
      "|    n_updates        | 7234     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 29160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.7     |\n",
      "|    n_updates        | 7264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 29280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.4     |\n",
      "|    n_updates        | 7294     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 29400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.1     |\n",
      "|    n_updates        | 7324     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 29520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28       |\n",
      "|    n_updates        | 7354     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 29640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.4     |\n",
      "|    n_updates        | 7384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 29760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.3     |\n",
      "|    n_updates        | 7414     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 29880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.1     |\n",
      "|    n_updates        | 7444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.5     |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 30120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.6     |\n",
      "|    n_updates        | 7504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 30240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.3     |\n",
      "|    n_updates        | 7534     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.62e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 30360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.9     |\n",
      "|    n_updates        | 7564     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 30480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 33.6     |\n",
      "|    n_updates        | 7594     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.63e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 30600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 7624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 30720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.3     |\n",
      "|    n_updates        | 7654     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 30840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.8     |\n",
      "|    n_updates        | 7684     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 30960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 7714     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 31080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 35.5     |\n",
      "|    n_updates        | 7744     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.1     |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 31320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.6     |\n",
      "|    n_updates        | 7804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 31440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 7834     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 31560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 34.7     |\n",
      "|    n_updates        | 7864     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 31680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.7     |\n",
      "|    n_updates        | 7894     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 31800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.9     |\n",
      "|    n_updates        | 7924     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 31920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.9     |\n",
      "|    n_updates        | 7954     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 32040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.8     |\n",
      "|    n_updates        | 7984     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 32160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.6     |\n",
      "|    n_updates        | 8014     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 32280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.2     |\n",
      "|    n_updates        | 8044     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 32400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.1     |\n",
      "|    n_updates        | 8074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 32520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.7     |\n",
      "|    n_updates        | 8104     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 32640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.6     |\n",
      "|    n_updates        | 8134     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 32760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32.1     |\n",
      "|    n_updates        | 8164     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 32880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.6     |\n",
      "|    n_updates        | 8194     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 33000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.4     |\n",
      "|    n_updates        | 8224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 33120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.3     |\n",
      "|    n_updates        | 8254     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 33240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.3     |\n",
      "|    n_updates        | 8284     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 33360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 8314     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 33480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.3     |\n",
      "|    n_updates        | 8344     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30       |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 33720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.8     |\n",
      "|    n_updates        | 8404     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 33840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.6     |\n",
      "|    n_updates        | 8434     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 33960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.3     |\n",
      "|    n_updates        | 8464     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 34080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 8494     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 34200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31       |\n",
      "|    n_updates        | 8524     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 34320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.8     |\n",
      "|    n_updates        | 8554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 34440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.4     |\n",
      "|    n_updates        | 8584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 34560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 30.4     |\n",
      "|    n_updates        | 8614     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 34680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.2     |\n",
      "|    n_updates        | 8644     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 34800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.9     |\n",
      "|    n_updates        | 8674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 34920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.9     |\n",
      "|    n_updates        | 8704     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 35040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.1     |\n",
      "|    n_updates        | 8734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 35160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.7     |\n",
      "|    n_updates        | 8764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 35280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.7     |\n",
      "|    n_updates        | 8794     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 35400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.9     |\n",
      "|    n_updates        | 8824     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 35520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.5     |\n",
      "|    n_updates        | 8854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 35640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.8     |\n",
      "|    n_updates        | 8884     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 35760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 32       |\n",
      "|    n_updates        | 8914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 35880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.2     |\n",
      "|    n_updates        | 8944     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.7     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 36120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24       |\n",
      "|    n_updates        | 9004     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 36240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.8     |\n",
      "|    n_updates        | 9034     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 36360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 31.2     |\n",
      "|    n_updates        | 9064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 36480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.1     |\n",
      "|    n_updates        | 9094     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 36600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.4     |\n",
      "|    n_updates        | 9124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 36720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.2     |\n",
      "|    n_updates        | 9154     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 36840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 29.3     |\n",
      "|    n_updates        | 9184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 36960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.4     |\n",
      "|    n_updates        | 9214     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.71e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 37080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.1     |\n",
      "|    n_updates        | 9244     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.71e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 37200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.1     |\n",
      "|    n_updates        | 9274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.71e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 37320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.5     |\n",
      "|    n_updates        | 9304     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.71e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 37440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 28.5     |\n",
      "|    n_updates        | 9334     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 37560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.8     |\n",
      "|    n_updates        | 9364     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 37680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.1     |\n",
      "|    n_updates        | 9394     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 37800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.8     |\n",
      "|    n_updates        | 9424     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.7e+03  |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 37920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.5     |\n",
      "|    n_updates        | 9454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 38040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.1     |\n",
      "|    n_updates        | 9484     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 38160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.5     |\n",
      "|    n_updates        | 9514     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 38280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.4     |\n",
      "|    n_updates        | 9544     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.7     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 38520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.4     |\n",
      "|    n_updates        | 9604     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 38640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.1     |\n",
      "|    n_updates        | 9634     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 38760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.7     |\n",
      "|    n_updates        | 9664     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 38880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22       |\n",
      "|    n_updates        | 9694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 39000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.3     |\n",
      "|    n_updates        | 9724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 39120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.5     |\n",
      "|    n_updates        | 9754     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 39240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.2     |\n",
      "|    n_updates        | 9784     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 39360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.8     |\n",
      "|    n_updates        | 9814     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 39480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.6     |\n",
      "|    n_updates        | 9844     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 39600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.8     |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 39720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.9     |\n",
      "|    n_updates        | 9904     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 39840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.9     |\n",
      "|    n_updates        | 9934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 39960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.7     |\n",
      "|    n_updates        | 9964     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 40080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.3     |\n",
      "|    n_updates        | 9994     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 40200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.3     |\n",
      "|    n_updates        | 10024    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 40320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.2     |\n",
      "|    n_updates        | 10054    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 40440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.5     |\n",
      "|    n_updates        | 10084    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 40560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.4     |\n",
      "|    n_updates        | 10114    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 40680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.1     |\n",
      "|    n_updates        | 10144    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.8     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 40920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.4     |\n",
      "|    n_updates        | 10204    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 41040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 26.4     |\n",
      "|    n_updates        | 10234    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 41160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.1     |\n",
      "|    n_updates        | 10264    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 41280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18       |\n",
      "|    n_updates        | 10294    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 41400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.3     |\n",
      "|    n_updates        | 10324    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 41520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.5     |\n",
      "|    n_updates        | 10354    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 41640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.8     |\n",
      "|    n_updates        | 10384    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 41760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.3     |\n",
      "|    n_updates        | 10414    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 41880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27       |\n",
      "|    n_updates        | 10444    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 27.4     |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.1     |\n",
      "|    n_updates        | 10504    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 42240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 25.1     |\n",
      "|    n_updates        | 10534    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 42360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.7     |\n",
      "|    n_updates        | 10564    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 42480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.7     |\n",
      "|    n_updates        | 10594    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 42600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.3     |\n",
      "|    n_updates        | 10624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 42720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.9     |\n",
      "|    n_updates        | 10654    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 42840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.8     |\n",
      "|    n_updates        | 10684    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 42960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.9     |\n",
      "|    n_updates        | 10714    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 43080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.1     |\n",
      "|    n_updates        | 10744    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.6     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 43320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.2     |\n",
      "|    n_updates        | 10804    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 43440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.8     |\n",
      "|    n_updates        | 10834    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 43560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.8     |\n",
      "|    n_updates        | 10864    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 43680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.1     |\n",
      "|    n_updates        | 10894    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 43800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.7     |\n",
      "|    n_updates        | 10924    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 43920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.6     |\n",
      "|    n_updates        | 10954    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 44040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.8     |\n",
      "|    n_updates        | 10984    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 44160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.6     |\n",
      "|    n_updates        | 11014    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 44280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.1     |\n",
      "|    n_updates        | 11044    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 44400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.6     |\n",
      "|    n_updates        | 11074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 44520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.6     |\n",
      "|    n_updates        | 11104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 44640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.3     |\n",
      "|    n_updates        | 11134    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 44760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.8     |\n",
      "|    n_updates        | 11164    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 44880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.1     |\n",
      "|    n_updates        | 11194    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.8     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 45120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19       |\n",
      "|    n_updates        | 11254    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 45240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.7     |\n",
      "|    n_updates        | 11284    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 45360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.2     |\n",
      "|    n_updates        | 11314    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 45480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.2     |\n",
      "|    n_updates        | 11344    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.9     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 45720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.3     |\n",
      "|    n_updates        | 11404    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 45840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.7     |\n",
      "|    n_updates        | 11434    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 45960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.6     |\n",
      "|    n_updates        | 11464    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 46080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.4     |\n",
      "|    n_updates        | 11494    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 46200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.8     |\n",
      "|    n_updates        | 11524    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 46320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23       |\n",
      "|    n_updates        | 11554    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 46440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.6     |\n",
      "|    n_updates        | 11584    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 46560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.1     |\n",
      "|    n_updates        | 11614    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 46680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 14.9     |\n",
      "|    n_updates        | 11644    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 46800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.7     |\n",
      "|    n_updates        | 11674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 46920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 24.5     |\n",
      "|    n_updates        | 11704    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 47040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.3     |\n",
      "|    n_updates        | 11734    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 47160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17       |\n",
      "|    n_updates        | 11764    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 47280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.6     |\n",
      "|    n_updates        | 11794    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 47400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.2     |\n",
      "|    n_updates        | 11824    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 47520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.2     |\n",
      "|    n_updates        | 11854    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 47640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 21.7     |\n",
      "|    n_updates        | 11884    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 47760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.6     |\n",
      "|    n_updates        | 11914    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 47880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.3     |\n",
      "|    n_updates        | 11944    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 22.8     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 48120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.5     |\n",
      "|    n_updates        | 12004    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 48240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 15       |\n",
      "|    n_updates        | 12034    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 48360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19       |\n",
      "|    n_updates        | 12064    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 48480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 20.6     |\n",
      "|    n_updates        | 12094    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 48600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.3     |\n",
      "|    n_updates        | 12124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 48720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.3     |\n",
      "|    n_updates        | 12154    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 48840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.4     |\n",
      "|    n_updates        | 12184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.65e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 48960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.7     |\n",
      "|    n_updates        | 12214    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 49080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 19.5     |\n",
      "|    n_updates        | 12244    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 49200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 18.5     |\n",
      "|    n_updates        | 12274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.66e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 49320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 15.7     |\n",
      "|    n_updates        | 12304    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 49440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 17.2     |\n",
      "|    n_updates        | 12334    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 49560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 23.2     |\n",
      "|    n_updates        | 12364    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 49680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 14.6     |\n",
      "|    n_updates        | 12394    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.67e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 49800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 14.8     |\n",
      "|    n_updates        | 12424    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30       |\n",
      "|    ep_rew_mean      | 1.68e+03 |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 49920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 16.5     |\n",
      "|    n_updates        | 12454    |\n",
      "----------------------------------\n",
      "Model saved to models/dqn_hospital_sb3.zip\n",
      "Mean reward: 1616.48 ± 94.91\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../env\")  # to read hospital_env.py\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ------------------------------\n",
    "# Set seeds for reproducibility\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- Create wrapped environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env.reset(seed=SEED)   # seed the environment here\n",
    "    env = Monitor(env)      # important for SB3 logging\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Create DQN agent ---\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",       # Fully connected NN\n",
    "    env,\n",
    "    learning_rate=5e-4,\n",
    "    gamma=0.95,\n",
    "    batch_size=64,\n",
    "    buffer_size=50000,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.1,\n",
    "    exploration_fraction=0.1,   # epsilon decay\n",
    "    target_update_interval=1000,\n",
    "    verbose=1,\n",
    "    seed=SEED                  # seed SB3 agent\n",
    ")\n",
    "\n",
    "# --- Train agent ---\n",
    "model.learn(total_timesteps=50000)\n",
    "\n",
    "# --- Save trained model ---\n",
    "model.save(\"../models/dqn_hospital_sb3\")\n",
    "print(\"Model saved to models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=50)\n",
    "print(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc33803-e332-474a-ad49-c27285ab9fc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(mean_rewards[-\u001b[32m1\u001b[39m] - mean_rewards[-\u001b[32m2\u001b[39m]) < threshold\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m model = DQN.load(\u001b[33m\"\u001b[39m\u001b[33m../models/dqn_hospital_sb3\u001b[39m\u001b[33m\"\u001b[39m, env=\u001b[43meval_env\u001b[49m)\n\u001b[32m     23\u001b[39m mean_rewards_history = []\n\u001b[32m     24\u001b[39m timesteps_history = []\n",
      "\u001b[31mNameError\u001b[39m: name 'eval_env' is not defined"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../env\")  # to read hospital_env.py\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "env = HospitalEnv\n",
    "def check_convergence(mean_rewards, threshold=10):\n",
    "    \"\"\"\n",
    "    Checks if the last two rewards differ by less than threshold.\n",
    "    Returns True = converged.\n",
    "    \"\"\"\n",
    "    if len(mean_rewards) < 2:\n",
    "        return False\n",
    "    return abs(mean_rewards[-1] - mean_rewards[-2]) < threshold\n",
    "\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "mean_rewards_history = []\n",
    "timesteps_history = []\n",
    "\n",
    "for t in range(0, 200000, 10000):  # evaluate every 10k timesteps\n",
    "    model = DQN.load(f\"checkpoints/model_{t}.zip\", env)\n",
    "    \n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
    "    mean_rewards_history.append(mean_reward)\n",
    "    timesteps_history.append(t)\n",
    "\n",
    "    print(f\"At {t} timesteps → {mean_reward}\")\n",
    "\n",
    "    if check_convergence(mean_rewards_history):\n",
    "        print(f\"\\nModel converged at ~{t} timesteps.\\n\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af6e0ca-4b5d-48ab-b874-e0a4cadcf934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 1450.20\n",
      "Average wait times (Red, Yellow, Green): 2.70, 3.35, 0.69\n",
      "Percentage served within thresholds (Red, Yellow, Green): 87.67%, 100.00%, 100.00%\n",
      "Queue stats (average and max lengths):\n",
      "  Red: avg=2.98, max=13.00\n",
      "  Yellow: avg=40.36, max=100.00\n",
      "  Green: avg=44.44, max=102.00\n",
      "Green fairness metric: 0.19\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Add environment path\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# -------------------------------\n",
    "# Create wrapped evaluation environment\n",
    "# -------------------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 logging wrapper\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained DQN model\n",
    "# -------------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation parameters\n",
    "# -------------------------------\n",
    "n_episodes = 10  # number of episodes to evaluate\n",
    "threshold_times = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "\n",
    "# Storage for metrics\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "green_fair_actions = []\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate model\n",
    "# -------------------------------\n",
    "for ep in range(n_episodes):\n",
    "    obs = eval_env.reset()  # only 1 value returned\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = eval_env.step(action)  # SB3 returns 4 values\n",
    "        episode_reward += reward[0]\n",
    "\n",
    "        # Access raw environment for metrics\n",
    "        env = eval_env.envs[0].unwrapped\n",
    "\n",
    "        # Record last served wait times\n",
    "        red_waits.append(env.last_served_wait_times[\"red\"])\n",
    "        yellow_waits.append(env.last_served_wait_times[\"yellow\"])\n",
    "        green_waits.append(env.last_served_wait_times[\"green\"])\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # GREEN fairness: if GREEN patient served in last 5 actions\n",
    "        green_fair_actions.append(1 if 2 in env.last_5_actions else 0)\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute metrics\n",
    "# -------------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "red_served = len(red_waits)\n",
    "yellow_served = len(yellow_waits)\n",
    "green_served = len(green_waits)\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = np.mean(green_fair_actions) if green_fair_actions else 0\n",
    "\n",
    "# -------------------------------\n",
    "# Print results with 2 decimals\n",
    "# -------------------------------\n",
    "print(f\"Average reward per episode: {avg_reward:.2f}\")\n",
    "print(f\"Average wait times (Red, Yellow, Green): {avg_wait_red:.2f}, {avg_wait_yellow:.2f}, {avg_wait_green:.2f}\")\n",
    "print(f\"Percentage served within thresholds (Red, Yellow, Green): {pct_red_within:.2f}%, {pct_yellow_within:.2f}%, {pct_green_within:.2f}%\")\n",
    "print(\"Queue stats (average and max lengths):\")\n",
    "for cat, stats in queue_stats.items():\n",
    "    print(f\"  {cat.capitalize()}: avg={stats['avg']:.2f}, max={stats['max']:.2f}\")\n",
    "print(f\"Green fairness metric: {fairness:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d072ba87-80ff-4327-8834-9d93f3df222b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_episodes):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     obs, _ = eval_env.reset()\n\u001b[32m     43\u001b[39m     done = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     44\u001b[39m     episode_reward = \u001b[32m0\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Add environment path\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# -------------------------------\n",
    "# Create wrapped evaluation environment\n",
    "# -------------------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 logging wrapper\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained DQN model\n",
    "# -------------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation parameters\n",
    "# -------------------------------\n",
    "n_episodes = 10  # number of episodes to evaluate\n",
    "threshold_times = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "\n",
    "# Storage for metrics\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "green_fair_actions = []\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate model\n",
    "# -------------------------------\n",
    "for ep in range(n_episodes):\n",
    "    obs, _ = eval_env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        episode_reward += reward[0]\n",
    "\n",
    "        # Access raw environment for metrics\n",
    "        env = eval_env.envs[0].unwrapped\n",
    "\n",
    "        # Record last served wait times only if a patient was actually served\n",
    "        served = False\n",
    "        queue_map = {0: env.red_queue, 1: env.yellow_queue, 2: env.green_queue}\n",
    "        if len(queue_map[action]) < len(queue_map[action]) + 1:  # patient removed\n",
    "            served = True\n",
    "\n",
    "        if served:\n",
    "            if action == 0:\n",
    "                red_waits.append(env.last_served_wait_times[\"red\"])\n",
    "            elif action == 1:\n",
    "                yellow_waits.append(env.last_served_wait_times[\"yellow\"])\n",
    "            elif action == 2:\n",
    "                green_waits.append(env.last_served_wait_times[\"green\"])\n",
    "\n",
    "        # Record queue lengths every step\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # Track GREEN fairness (if GREEN patient served recently)\n",
    "        green_fair_actions.append(1 if 2 in env.last_5_actions else 0)\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute metrics\n",
    "# -------------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "red_served = len(red_waits)\n",
    "yellow_served = len(yellow_waits)\n",
    "green_served = len(green_waits)\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "fairness = np.mean(green_fair_actions) if green_fair_actions else 0\n",
    "\n",
    "# -------------------------------\n",
    "# Print results with 2 decimals\n",
    "# -------------------------------\n",
    "print(f\"Average reward per episode: {avg_reward:.2f}\")\n",
    "print(f\"Average wait times (Red, Yellow, Green): {avg_wait_red:.2f}, {avg_wait_yellow:.2f}, {avg_wait_green:.2f}\")\n",
    "print(f\"Percentage served within thresholds (Red, Yellow, Green): {pct_red_within:.2f}%, {pct_yellow_within:.2f}%, {pct_green_within:.2f}%\")\n",
    "print(\"Queue stats (average and max lengths):\")\n",
    "for cat, stats in queue_stats.items():\n",
    "    print(f\"  {cat.capitalize()}: avg={stats['avg']:.2f}, max={stats['max']:.2f}\")\n",
    "print(f\"Green fairness metric: {fairness:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4794ce2-2f22-4de9-98f3-93d8892ce6f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (983217891.py, line 85)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w i_*\u001b[39m\n                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Add environment path\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# -------------------------------\n",
    "# Create wrapped evaluation environment\n",
    "# -------------------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 logging wrapper\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained DQN model\n",
    "# -------------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation parameters\n",
    "# -------------------------------\n",
    "n_episodes = 10  # number of episodes to evaluate\n",
    "threshold_times = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "\n",
    "# Storage for metrics\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "green_fair_actions = []\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate model\n",
    "# -------------------------------\n",
    "for ep in range(n_episodes):\n",
    "    obs = eval_env.reset()  # only obs returned\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = eval_env.step(action)  # 4 values for SB3\n",
    "        episode_reward += reward[0]\n",
    "\n",
    "        # Access raw environment for metrics\n",
    "        env = eval_env.envs[0].unwrapped\n",
    "\n",
    "        # Record last served wait times (only if patient served)\n",
    "        if env.last_served_wait_times[\"red\"] > 0:\n",
    "            red_waits.append(env.last_served_wait_times[\"red\"])\n",
    "        if env.last_served_wait_times[\"yellow\"] > 0:\n",
    "            yellow_waits.append(env.last_served_wait_times[\"yellow\"])\n",
    "        if env.last_served_wait_times[\"green\"] > 0:\n",
    "            green_waits.append(env.last_served_wait_times[\"green\"])\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # Track GREEN fairness (if GREEN patient served recently)\n",
    "        green_fair_actions.append(1 if 2 in env.last_5_actions else 0)\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute metrics\n",
    "# -------------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "red_served = len(red_waits)\n",
    "yellow_served = len(yellow_waits)\n",
    "green_served = len(green_waits)\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w i_*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4809d9e7-8a62-4434-abd5-b5fc90176079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 1450.20\n",
      "Average wait times (Red, Yellow, Green): 3.03, 4.33, 9.90\n",
      "Percentage served within thresholds (Red, Yellow, Green): 86.19%, 100.00%, 100.00%\n",
      "Queue stats (average and max lengths):\n",
      "  Red: avg=2.98, max=13.00\n",
      "  Yellow: avg=40.36, max=100.00\n",
      "  Green: avg=44.44, max=102.00\n",
      "Green fairness metric: 0.19\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Add environment path\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# -------------------------------\n",
    "# Create wrapped evaluation environment\n",
    "# -------------------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 logging wrapper\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained DQN model\n",
    "# -------------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation parameters\n",
    "# -------------------------------\n",
    "n_episodes = 10  # number of episodes to evaluate\n",
    "threshold_times = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "\n",
    "# Storage for metrics\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "green_fair_actions = []\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate model\n",
    "# -------------------------------\n",
    "for ep in range(n_episodes):\n",
    "    obs = eval_env.reset()  # only obs returned\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = eval_env.step(action)  # 4 values for SB3\n",
    "        episode_reward += reward[0]\n",
    "\n",
    "        # Access raw environment for metrics\n",
    "        env = eval_env.envs[0].unwrapped\n",
    "\n",
    "        # Record last served wait times (only if patient served)\n",
    "        if env.last_served_wait_times[\"red\"] > 0:\n",
    "            red_waits.append(env.last_served_wait_times[\"red\"])\n",
    "        if env.last_served_wait_times[\"yellow\"] > 0:\n",
    "            yellow_waits.append(env.last_served_wait_times[\"yellow\"])\n",
    "        if env.last_served_wait_times[\"green\"] > 0:\n",
    "            green_waits.append(env.last_served_wait_times[\"green\"])\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # Track GREEN fairness (if GREEN patient served recently)\n",
    "        green_fair_actions.append(1 if 2 in env.last_5_actions else 0)\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute metrics\n",
    "# -------------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "red_served = len(red_waits)\n",
    "yellow_served = len(yellow_waits)\n",
    "green_served = len(green_waits)\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = np.mean(green_fair_actions) if green_fair_actions else 0\n",
    "\n",
    "# -------------------------------\n",
    "# Print results with 2 decimals\n",
    "# -------------------------------\n",
    "print(f\"Average reward per episode: {avg_reward:.2f}\")\n",
    "print(f\"Average wait times (Red, Yellow, Green): {avg_wait_red:.2f}, {avg_wait_yellow:.2f}, {avg_wait_green:.2f}\")\n",
    "print(f\"Percentage served within thresholds (Red, Yellow, Green): {pct_red_within:.2f}%, {pct_yellow_within:.2f}%, {pct_green_within:.2f}%\")\n",
    "print(\"Queue stats (average and max lengths):\")\n",
    "for cat, stats in queue_stats.items():\n",
    "    print(f\"  {cat.capitalize()}: avg={stats['avg']:.2f}, max={stats['max']:.2f}\")\n",
    "print(f\"Green fairness metric: {fairness:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76592924-4de3-4a62-9496-c1ca3ad09b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 1635.10\n",
      "Average possible reward per episode: 2413.00\n",
      "Average wait times (Red, Yellow, Green): 3.42, 4.80, 6.39\n",
      "Percentage served within thresholds (Red, Yellow, Green): 100.00%, 100.00%, 100.00%\n",
      "Queue stats (average and max lengths):\n",
      "  Red: avg=3.48, max=12.00\n",
      "  Yellow: avg=41.00, max=98.00\n",
      "  Green: avg=42.79, max=103.00\n",
      "Fairness (GREEN served / total served): 0.27\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 0 timesteps → 1635.1\n",
      "At 10000 timesteps → 1556.8\n",
      "At 20000 timesteps → 1615.2\n",
      "At 30000 timesteps → 1584.4\n",
      "At 40000 timesteps → 1677.0\n",
      "At 50000 timesteps → 1636.7\n",
      "At 60000 timesteps → 1627.2\n",
      "\n",
      "Model converged at ~60000 timesteps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Add environment path\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# -------------------------------\n",
    "# Create wrapped evaluation environment\n",
    "# -------------------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 logging wrapper\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# -------------------------------\n",
    "# Load trained DQN model\n",
    "# -------------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation parameters\n",
    "# -------------------------------\n",
    "n_episodes = 10  # number of episodes to evaluate\n",
    "threshold_times = {\"red\": 10, \"yellow\": 30, \"green\": 60}\n",
    "reward_map = {\"red\": 30, \"yellow\": 20, \"green\": 5}\n",
    "reward_bonus = {\"red\": 25, \"yellow\": 15, \"green\": 5}\n",
    "\n",
    "# Storage for metrics\n",
    "rewards_per_episode = []\n",
    "total_possible_rewards = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "green_served_count = 0\n",
    "total_served_count = 0\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate model\n",
    "# -------------------------------\n",
    "for ep in range(n_episodes):\n",
    "    obs = eval_env.reset()  # only obs returned\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    episode_possible_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = eval_env.step(action)\n",
    "        episode_reward += reward[0]\n",
    "\n",
    "        # Access raw environment\n",
    "        env = eval_env.envs[0].unwrapped\n",
    "\n",
    "        # Record last served wait times and compute possible rewards\n",
    "        if env.last_served_wait_times[\"red\"] > 0:\n",
    "            red_waits.append(env.last_served_wait_times[\"red\"])\n",
    "            episode_possible_reward += reward_map[\"red\"] + reward_bonus[\"red\"]\n",
    "            total_served_count += 1\n",
    "        if env.last_served_wait_times[\"yellow\"] > 0:\n",
    "            yellow_waits.append(env.last_served_wait_times[\"yellow\"])\n",
    "            episode_possible_reward += reward_map[\"yellow\"] + reward_bonus[\"yellow\"]\n",
    "            total_served_count += 1\n",
    "        if env.last_served_wait_times[\"green\"] > 0:\n",
    "            green_waits.append(env.last_served_wait_times[\"green\"])\n",
    "            episode_possible_reward += reward_map[\"green\"] + reward_bonus[\"green\"]\n",
    "            green_served_count += 1\n",
    "            total_served_count += 1\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "    rewards_per_episode.append(episode_reward)\n",
    "    total_possible_rewards.append(episode_possible_reward)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute metrics\n",
    "# -------------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_possible = np.mean(total_possible_rewards)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / len(red_waits) if red_waits else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / len(yellow_waits) if yellow_waits else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / len(green_waits) if green_waits else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "# Fairness: GREEN patients served / total served\n",
    "fairness = green_served_count / total_served_count if total_served_count > 0 else 0\n",
    "\n",
    "# -------------------------------\n",
    "# Print results\n",
    "# -------------------------------\n",
    "print(f\"Average reward per episode: {avg_reward:.2f}\")\n",
    "print(f\"Average possible reward per episode: {avg_possible:.2f}\")\n",
    "print(f\"Average wait times (Red, Yellow, Green): {avg_wait_red:.2f}, {avg_wait_yellow:.2f}, {avg_wait_green:.2f}\")\n",
    "print(f\"Percentage served within thresholds (Red, Yellow, Green): {pct_red_within:.2f}%, {pct_yellow_within:.2f}%, {pct_green_within:.2f}%\")\n",
    "print(\"Queue stats (average and max lengths):\")\n",
    "for cat, stats in queue_stats.items():\n",
    "    print(f\"  {cat.capitalize()}: avg={stats['avg']:.2f}, max={stats['max']:.2f}\")\n",
    "print(f\"Fairness (GREEN served / total served): {fairness:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4f8f36-b7cd-4497-98b2-1d6bf68b5435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "At 0 timesteps → mean reward: 1635.10\n",
      "At 10000 timesteps → mean reward: 1556.80\n",
      "At 20000 timesteps → mean reward: 1615.20\n",
      "At 30000 timesteps → mean reward: 1584.40\n",
      "At 40000 timesteps → mean reward: 1677.00\n",
      "At 50000 timesteps → mean reward: 1636.70\n",
      "At 60000 timesteps → mean reward: 1627.20\n",
      "\n",
      "Model converged at ~60000 timesteps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from hospital_env import HospitalEnv  # replace with your actual path\n",
    "\n",
    "# 1️⃣ Create and wrap environment\n",
    "env = HospitalEnv()\n",
    "env = Monitor(env)\n",
    "\n",
    "# 2️⃣ Convergence check function\n",
    "def check_convergence(mean_rewards, threshold=10):\n",
    "    \"\"\"\n",
    "    Checks if the last two rewards differ by less than threshold.\n",
    "    Returns True = converged.\n",
    "    \"\"\"\n",
    "    if len(mean_rewards) < 2:\n",
    "        return False\n",
    "    return abs(mean_rewards[-1] - mean_rewards[-2]) < threshold\n",
    "\n",
    "# 3️⃣ Load your trained model (first one)\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=env)\n",
    "\n",
    "# 4️⃣ Evaluate over timesteps\n",
    "mean_rewards_history = []\n",
    "timesteps_history = []\n",
    "\n",
    "for t in range(0, 200000, 10000):  # adjust based on saved checkpoints\n",
    "    # If you have separate checkpoints, load each one like this:\n",
    "    # model = DQN.load(f\"../models/checkpoints/model_{t}\", env=env)\n",
    "    \n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
    "    mean_rewards_history.append(mean_reward)\n",
    "    timesteps_history.append(t)\n",
    "\n",
    "    print(f\"At {t} timesteps → mean reward: {mean_reward:.2f}\")\n",
    "\n",
    "    if check_convergence(mean_rewards_history):\n",
    "        print(f\"\\nModel converged at ~{t} timesteps.\\n\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7173f084-421c-4980-b583-76da4a124117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "Model loaded successfully!\n",
      "\n",
      "Final Evaluation → Mean Reward: 1595.95 | Std: 149.98\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m     51\u001b[39m     action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     obs, reward, terminated, truncated, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m     54\u001b[39m     episode_reward += reward\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[39m, in \u001b[36mMonitor.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.needs_reset:\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTried to step environment that needs reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.rewards.append(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\RL_Project_New\\env\\hospital_env.py:133\u001b[39m, in \u001b[36mHospitalEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Map action to queue\u001b[39;00m\n\u001b[32m    130\u001b[39m queue_map = {\u001b[32m0\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.red_queue),\n\u001b[32m    131\u001b[39m              \u001b[32m1\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33myellow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.yellow_queue),\n\u001b[32m    132\u001b[39m              \u001b[32m2\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.green_queue)}\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m cat_name, queue = \u001b[43mqueue_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# If queue empty → 0 reward\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queue) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# ----------------------------\n",
    "# 1. IMPORT YOUR CUSTOM ENV\n",
    "# ----------------------------\n",
    "from hospital_env import HospitalEnv   # <-- make sure this matches your file name\n",
    "\n",
    "# ----------------------------\n",
    "# 2. CREATE ENVIRONMENT\n",
    "# ----------------------------\n",
    "env = HospitalEnv()\n",
    "env = Monitor(env)   # fixes the warning\n",
    "\n",
    "# ----------------------------\n",
    "# 3. LOAD TRAINED MODEL\n",
    "# ----------------------------\n",
    "model_path = \"../models/dqn_hospital_sb3.zip\"   # your saved model\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model not found at: {model_path}\")\n",
    "\n",
    "model = DQN.load(model_path, env=env)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. EVALUATE MODEL\n",
    "# ----------------------------\n",
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model,\n",
    "    env,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Evaluation → Mean Reward: {mean_reward:.2f} | Std: {std_reward:.2f}\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. OPTIONAL: RUN ONE EPISODE\n",
    "# ----------------------------\n",
    "obs, _ = env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    episode_reward += reward\n",
    "\n",
    "print(f\"One Demo Episode Reward: {episode_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8afcfc5-fa8e-47f9-9784-37803d46137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "Mean reward over 10 episodes: 1635.10\n",
      "Standard deviation of reward: 138.76\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\models\\\\checkpoints\\\\model_0.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m checkpoints:\n\u001b[32m     36\u001b[39m     checkpoint_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m../models/checkpoints/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# no .zip added if already saved\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     checkpoint_model = \u001b[43mDQN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     mean_r, _ = evaluate_policy(checkpoint_model, env, n_eval_episodes=\u001b[32m5\u001b[39m, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     39\u001b[39m     mean_rewards_history.append(mean_r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:681\u001b[39m, in \u001b[36mBaseAlgorithm.load\u001b[39m\u001b[34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m     get_system_info()\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m data, params, pytorch_variables = \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo data found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo params found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:403\u001b[39m, in \u001b[36mload_from_zip_file\u001b[39m\u001b[34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_zip_file\u001b[39m(\n\u001b[32m    377\u001b[39m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib.Path, io.BufferedIOBase],\n\u001b[32m    378\u001b[39m     load_data: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     print_system_info: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[32m    386\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     file = \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[32m    406\u001b[39m     device = get_device(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\functools.py:912\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    909\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    910\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:240\u001b[39m, in \u001b[36mopen_path_str\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@open_path\u001b[39m.register(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> io.BufferedIOBase:\n\u001b[32m    227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m    that the path exists.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    238\u001b[39m \u001b[33;03m    :return:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:291\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    285\u001b[39m         path.parent.mkdir(exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m, parents=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:272\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    270\u001b[39m             path, suffix = newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:264\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\pathlib.py:1013\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1012\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\models\\\\checkpoints\\\\model_0.zip'"
     ]
    }
   ],
   "source": [
    "# evaluation_hospital.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# 1️⃣ Import your custom environment\n",
    "from hospital_env import HospitalEnv  # replace with your actual file/path\n",
    "\n",
    "# 2️⃣ Create the environment and wrap with Monitor\n",
    "env = HospitalEnv()\n",
    "env = Monitor(env)\n",
    "\n",
    "# 3️⃣ Load your trained model\n",
    "model_path = \"../models/dqn_hospital_sb3\"  # path to your saved DQN\n",
    "model = DQN.load(model_path, env=env)\n",
    "\n",
    "# 4️⃣ Evaluate the model\n",
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model,\n",
    "    env,\n",
    "    n_eval_episodes=10,    # number of evaluation episodes\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "print(f\"Mean reward over 10 episodes: {mean_reward:.2f}\")\n",
    "print(f\"Standard deviation of reward: {std_reward:.2f}\")\n",
    "\n",
    "# 5️⃣ Optional: Track convergence over multiple checkpoints\n",
    "# Example: checkpoints saved during training\n",
    "checkpoints = [0, 10000, 20000, 30000]  # replace with your actual saved checkpoints\n",
    "mean_rewards_history = []\n",
    "\n",
    "for t in checkpoints:\n",
    "    checkpoint_path = f\"../models/checkpoints/model_{t}\"  # no .zip added if already saved\n",
    "    checkpoint_model = DQN.load(checkpoint_path, env=env)\n",
    "    mean_r, _ = evaluate_policy(checkpoint_model, env, n_eval_episodes=5, deterministic=True)\n",
    "    mean_rewards_history.append(mean_r)\n",
    "    print(f\"At {t} timesteps → mean reward: {mean_r:.2f}\")\n",
    "\n",
    "# 6️⃣ Plot convergence curve\n",
    "plt.plot(checkpoints, mean_rewards_history, marker='o')\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.title(\"Convergence Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573cd4e0-838e-4200-b175-b3defbde7d3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../models/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m checkpoints_folder = \u001b[33m\"\u001b[39m\u001b[33m../models/checkpoints\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 4️⃣ List all checkpoint files\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m all_files = \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoints_folder\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     20\u001b[39m checkpoint_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m all_files \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checkpoint_files:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '../models/checkpoints'"
     ]
    }
   ],
   "source": [
    "# auto_evaluate_hospital.py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# 1️⃣ Import your custom environment\n",
    "from hospital_env import HospitalEnv  # replace with your actual file/path\n",
    "\n",
    "# 2️⃣ Create environment and wrap with Monitor\n",
    "env = HospitalEnv()\n",
    "env = Monitor(env)\n",
    "\n",
    "# 3️⃣ Folder containing checkpoints\n",
    "checkpoints_folder = \"../models/checkpoints\"\n",
    "\n",
    "# 4️⃣ List all checkpoint files\n",
    "all_files = sorted(os.listdir(checkpoints_folder))\n",
    "checkpoint_files = [f for f in all_files if f.endswith(\".zip\")]\n",
    "\n",
    "if not checkpoint_files:\n",
    "    print(\"No checkpoint files found in:\", checkpoints_folder)\n",
    "    exit()\n",
    "\n",
    "print(\"Found checkpoints:\", checkpoint_files)\n",
    "\n",
    "# 5️⃣ Evaluate each checkpoint\n",
    "mean_rewards_history = []\n",
    "for file in checkpoint_files:\n",
    "    checkpoint_path = os.path.join(checkpoints_folder, file)\n",
    "    print(f\"\\nEvaluating {file} ...\")\n",
    "    \n",
    "    model = DQN.load(checkpoint_path, env=env)\n",
    "    \n",
    "    mean_r, std_r = evaluate_policy(\n",
    "        model,\n",
    "        env,\n",
    "        n_eval_episodes=5,   # adjust as needed\n",
    "        deterministic=True\n",
    "    )\n",
    "    mean_rewards_history.append(mean_r)\n",
    "    print(f\"Mean reward: {mean_r:.2f}, Std: {std_r:.2f}\")\n",
    "\n",
    "# 6️⃣ Plot convergence curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(checkpoint_files)), mean_rewards_history, marker='o')\n",
    "plt.xticks(range(len(checkpoint_files)), checkpoint_files, rotation=45)\n",
    "plt.xlabel(\"Checkpoints\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.title(\"Convergence Curve of DQN on HospitalEnv\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0961361c-5f60-4aa3-bfb6-a043ae0860e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints folder not found: C:\\rl_env\\models\\checkpoints\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\rl_env\\\\models\\\\checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     exit()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 5️⃣ List all checkpoint files\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m all_files = \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoints_folder\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     25\u001b[39m checkpoint_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m all_files \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checkpoint_files:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'C:\\\\rl_env\\\\models\\\\checkpoints'"
     ]
    }
   ],
   "source": [
    "# auto_evaluate_hospital_windows.py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# 1️⃣ Import your custom environment\n",
    "from hospital_env import HospitalEnv  # replace with your actual file/path\n",
    "\n",
    "# 2️⃣ Create the environment and wrap with Monitor\n",
    "env = HospitalEnv()\n",
    "env = Monitor(env)\n",
    "\n",
    "# 3️⃣ Absolute path to the checkpoints folder (update this to your folder)\n",
    "checkpoints_folder = r\"C:\\rl_env\\models\\checkpoints\"  # <-- change to your actual path\n",
    "\n",
    "# 4️⃣ Verify the folder exists\n",
    "if not os.path.exists(checkpoints_folder):\n",
    "    print(\"Checkpoints folder not found:\", checkpoints_folder)\n",
    "    exit()\n",
    "\n",
    "# 5️⃣ List all checkpoint files\n",
    "all_files = sorted(os.listdir(checkpoints_folder))\n",
    "checkpoint_files = [f for f in all_files if f.endswith(\".zip\")]\n",
    "\n",
    "if not checkpoint_files:\n",
    "    print(\"No checkpoint files found in:\", checkpoints_folder)\n",
    "    exit()\n",
    "\n",
    "print(\"Found checkpoints:\", checkpoint_files)\n",
    "\n",
    "# 6️⃣ Evaluate each checkpoint\n",
    "mean_rewards_history = []\n",
    "\n",
    "for file in checkpoint_files:\n",
    "    checkpoint_path = os.path.join(checkpoints_folder, file)\n",
    "    print(f\"\\nEvaluating {file} ...\")\n",
    "    \n",
    "    model = DQN.load(checkpoint_path, env=env)\n",
    "    \n",
    "    mean_r, std_r = evaluate_policy(\n",
    "        model,\n",
    "        env,\n",
    "        n_eval_episodes=5,   # number of evaluation episodes\n",
    "        deterministic=True\n",
    "    )\n",
    "    mean_rewards_history.append(mean_r)\n",
    "    print(f\"Mean reward: {mean_r:.2f}, Std: {std_r:.2f}\")\n",
    "\n",
    "# 7️⃣ Plot convergence curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(checkpoint_files)), mean_rewards_history, marker='o')\n",
    "plt.xticks(range(len(checkpoint_files)), checkpoint_files, rotation=45)\n",
    "plt.xlabel(\"Checkpoints\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.title(\"Convergence Curve of DQN on HospitalEnv\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7eef2c-8f17-44cf-9868-091fd70d9266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl_env)",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
