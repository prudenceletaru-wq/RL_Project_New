{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe084e-5131-4b4b-927e-936c89436c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_project/\n",
    "│\n",
    "├── hospital_env.py        # Your environment (already exists)\n",
    "├── train_agent.py         # Train DQN agent\n",
    "├── evaluate.py            # Evaluate trained model\n",
    "├── serve_api.py           # REST API using FastAPI\n",
    "├── requirements.txt\n",
    "└── Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883ae64-e208-43b2-b16d-f030ea98e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hospital_env import HospitalEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class RewardLogger(BaseCallback):\n",
    "    def __init__(self, log_interval=1, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.rewards = []\n",
    "        self.episode_rewards = []\n",
    "        self.log_interval = log_interval\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.locals.get(\"done\"):\n",
    "            ep_reward = self.locals[\"infos\"][0].get(\"episode_reward\", 0)\n",
    "            self.episode_rewards.append(ep_reward)\n",
    "        return True\n",
    "\n",
    "    def save_plot(self, path=\"reward_plot.png\"):\n",
    "        plt.plot(self.episode_rewards)\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title(\"Training Reward Over Time\")\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def train():\n",
    "    env = HospitalEnv()\n",
    "\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        learning_rate=1e-4,\n",
    "        buffer_size=50000,\n",
    "        learning_starts=100,\n",
    "        batch_size=32,\n",
    "        gamma=0.99,\n",
    "        train_freq=1,\n",
    "        target_update_interval=300,\n",
    "    )\n",
    "\n",
    "    logger = RewardLogger()\n",
    "\n",
    "    model.learn(total_timesteps=50_000, callback=logger)\n",
    "\n",
    "    logger.save_plot()\n",
    "\n",
    "    model.save(\"dqn_hospital_agent\")\n",
    "    print(\"Model saved to dqn_hospital_agent.zip\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aeb234-ddde-432f-89f0-ca750dbf5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hospital_env import HospitalEnv\n",
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load trained agent\n",
    "model = DQN.load(\"dqn_hospital_agent\")\n",
    "env = HospitalEnv()\n",
    "\n",
    "# Metrics storage\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # Record wait times for fairness & thresholds\n",
    "        last_waits = getattr(env, \"last_served_wait_times\", {})  # assume you save these in env\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# Compute metrics\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits)\n",
    "avg_wait_yellow = np.mean(yellow_waits)\n",
    "avg_wait_green = np.mean(green_waits)\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = 1 - (max(avg_wait_red, avg_wait_yellow, avg_wait_green) - min(avg_wait_red, avg_wait_yellow, avg_wait_green)) / max(avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "\n",
    "# Print results\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats:\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603324db-bc7d-4392-bfe9-cef130f05296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "model = DQN.load(\"dqn_hospital_agent\")\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    state: list   # 10 numbers\n",
    "\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_action(data: Observation):\n",
    "    obs = np.array(data.state).astype(float)\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    return {\"action\": int(action)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ad641-0849-4556-97d2-e3705ebd90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2027f-c748-42e7-97b7-c347b7fab5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvicorn serve_api:app --reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf182673-23d2-4bf7-8b4c-0732c6ffe9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "\n",
    "mlxtend==0.23.4\n",
    "mpmath==1.3.0\n",
    "namex==0.1.0\n",
    "networkx==3.6\n",
    "numpy==2.2.6\n",
    "opencv-python==4.12.0.88\n",
    "openpyxl==3.1.5\n",
    "opt_einsum==3.4.0\n",
    "optree==0.18.0\n",
    "packaging==25.0\n",
    "pandas==2.3.3\n",
    "pillow==12.0.0\n",
    "protobuf==6.33.1\n",
    "pydantic==2.12.4\n",
    "pydantic_core==2.41.5\n",
    "pygame==2.6.1\n",
    "pyparsing==3.2.5\n",
    "python-dateutil==2.9.0.post0\n",
    "pytz==2025.2\n",
    "setuptools==80.9.0\n",
    "six==1.17.0\n",
    "sniffio==1.3.1\n",
    "stable_baselines3==2.7.0\n",
    "starlette==0.50.0\n",
    "sympy==1.14.0\n",
    "tensorboard==2.20.0\n",
    "tensorboard-data-server==0.7.2\n",
    "termcolor==3.2.0\n",
    "torch==2.9.1+cpu\n",
    "torchaudio==2.9.1+cpu\n",
    "torchvision==0.24.1+cpu\n",
    "typing-inspection==0.4.2\n",
    "typing_extensions==4.15.0\n",
    "tzdata==2025.2\n",
    "uri-template==1.3.0\n",
    "uvicorn==0.38.0\n",
    "webcolors==25.10.0\n",
    "wheel==0.45.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f8cb7-8eec-481e-9799-9c127d24df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python:3.10\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . .\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"serve_api:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
