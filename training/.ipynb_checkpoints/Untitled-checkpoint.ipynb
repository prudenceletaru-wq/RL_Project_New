{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2012b52f-30f9-44be-9d8c-fd193e381e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1243     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 400      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.62     |\n",
      "|    n_updates        | 74       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1178     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 800      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1119     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1096     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.47e-06 |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1045     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.18e-10 |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1032     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000871 |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1008     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.59e-08 |\n",
      "|    n_updates        | 674      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.062    |\n",
      "|    n_updates        | 774      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 917      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.49e-06 |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.13e-11 |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.06e-07 |\n",
      "|    n_updates        | 1074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.6e-09  |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 5200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0365   |\n",
      "|    n_updates        | 1274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 5600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.77e-07 |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.67e-11 |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 849      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000303 |\n",
      "|    n_updates        | 1574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 847      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 6800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.23e-09 |\n",
      "|    n_updates        | 1674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 7600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.44e-08 |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.05e-11 |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 819      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000214 |\n",
      "|    n_updates        | 2074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 813      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 8800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.7e-09  |\n",
      "|    n_updates        | 2174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 9200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 2274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.14e-07 |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.09e-11 |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 10400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.71e-05 |\n",
      "|    n_updates        | 2574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 10800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.3e-08  |\n",
      "|    n_updates        | 2674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 11200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 2774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 803      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 11600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.26e-06 |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 803      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.87e-11 |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 12400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.08e-05 |\n",
      "|    n_updates        | 3074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 12800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.44e-10 |\n",
      "|    n_updates        | 3174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 13200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 3274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 807      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 13600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.6e-07  |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.82e-12 |\n",
      "|    n_updates        | 3474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 807      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.62e-05 |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 14800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.6e-10  |\n",
      "|    n_updates        | 3674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 15200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 3774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 809      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 15600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.02e-07 |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2e-11    |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 16400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.79e-05 |\n",
      "|    n_updates        | 4074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.74e-09 |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 17200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 4274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 17600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.32e-06 |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.23e-11 |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 18400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.28e-05 |\n",
      "|    n_updates        | 4574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 18800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.95e-08 |\n",
      "|    n_updates        | 4674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 803      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00741  |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 801      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 19600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.09e-07 |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.46e-11 |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 797      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 20400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.83e-05 |\n",
      "|    n_updates        | 5074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 797      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 20800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.46e-11 |\n",
      "|    n_updates        | 5174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 797      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 21200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 5274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 797      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.08e-07 |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4e-11    |\n",
      "|    n_updates        | 5474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 22400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.87e-05 |\n",
      "|    n_updates        | 5574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 802      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 22800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.64e-09 |\n",
      "|    n_updates        | 5674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 802      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 23200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 5774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 803      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 23600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.14e-07 |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 805      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.28e-11 |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 24400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.41e-05 |\n",
      "|    n_updates        | 6074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 801      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 24800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.46e-10 |\n",
      "|    n_updates        | 6174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 25200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 6274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 796      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 25600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.07e-07 |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 794      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.18e-10 |\n",
      "|    n_updates        | 6474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 794      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.68e-05 |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 26800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.31e-09 |\n",
      "|    n_updates        | 6674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 792      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 27200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 6774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 27600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.41e-08 |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0        |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 28400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.98e-05 |\n",
      "|    n_updates        | 7074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.53e-10 |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 29200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000181 |\n",
      "|    n_updates        | 7274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 29600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.91e-08 |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.02e-10 |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 30400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.69e-05 |\n",
      "|    n_updates        | 7574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 30800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.01e-09 |\n",
      "|    n_updates        | 7674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 787      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00595  |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 785      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 31600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.36e-08 |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.38e-10 |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 782      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 32400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.81e-05 |\n",
      "|    n_updates        | 8074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 781      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 32800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.12e-09 |\n",
      "|    n_updates        | 8174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 33200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 8274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.81e-07 |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.37e-10 |\n",
      "|    n_updates        | 8474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 34400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.37e-06 |\n",
      "|    n_updates        | 8574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 34800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.55e-09 |\n",
      "|    n_updates        | 8674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 35200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 8774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 35600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.46e-08 |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.36e-10 |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 36400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.16e-06 |\n",
      "|    n_updates        | 9074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 36800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.99e-09 |\n",
      "|    n_updates        | 9174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 37200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 9274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 37600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.69e-08 |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 781      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.76e-10 |\n",
      "|    n_updates        | 9474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 782      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.54e-06 |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 782      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 38800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.57e-10 |\n",
      "|    n_updates        | 9674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 39200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 9774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 39600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.62e-07 |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.69e-10 |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 40400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.56e-06 |\n",
      "|    n_updates        | 10074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.93e-10 |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 41200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000174 |\n",
      "|    n_updates        | 10274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 41600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.53e-09 |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0        |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 42400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.62e-05 |\n",
      "|    n_updates        | 10574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 785      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 42800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.77e-10 |\n",
      "|    n_updates        | 10674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 785      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000317 |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 786      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 43600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.46e-07 |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 786      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.89e-10 |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 787      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 44400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.31e-05 |\n",
      "|    n_updates        | 11074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 788      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 44800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.58e-10 |\n",
      "|    n_updates        | 11174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 788      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000184 |\n",
      "|    n_updates        | 11274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.19e-07 |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.8e-10  |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 46400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.31e-05 |\n",
      "|    n_updates        | 11574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 46800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.31e-10 |\n",
      "|    n_updates        | 11674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 47200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 11774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 47600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.93e-08 |\n",
      "|    n_updates        | 11874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.35e-10 |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 792      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 48400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.89e-05 |\n",
      "|    n_updates        | 12074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 793      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 48800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.18e-09 |\n",
      "|    n_updates        | 12174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 793      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 49200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 12274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 793      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 49600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.8e-07  |\n",
      "|    n_updates        | 12374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 794      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.08e-10 |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "Model saved to models/dqn_hospital_sb3.zip\n",
      "Mean reward: 1000.00  0.00\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../env\")  # to read hospital_env.py\n",
    "\n",
    "from hospital_env import HospitalEnv\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ------------------------------\n",
    "# Set seeds for reproducibility\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- Create wrapped environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env.reset(seed=SEED)   # seed the environment here\n",
    "    env = Monitor(env)      # important for SB3 logging\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Create DQN agent ---\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",       # Fully connected NN\n",
    "    env,\n",
    "    learning_rate=5e-4,\n",
    "    gamma=0.95,\n",
    "    batch_size=64,\n",
    "    buffer_size=50000,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.1,\n",
    "    exploration_fraction=0.1,   # epsilon decay\n",
    "    target_update_interval=1000,\n",
    "    verbose=1,\n",
    "    seed=SEED                  # seed SB3 agent\n",
    ")\n",
    "\n",
    "# --- Train agent ---\n",
    "model.learn(total_timesteps=50000)\n",
    "\n",
    "# --- Save trained model ---\n",
    "model.save(\"../models/dqn_hospital_sb3\")\n",
    "print(\"Model saved to models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=50)\n",
    "print(f\"Mean reward: {mean_reward:.2f}  {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec109e4-bac3-4e1a-aa56-f2d48326f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "class HospitalEnv(gym.Env):\n",
    "    def __init__(self, num_doctors=3, max_steps=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_doctors = num_doctors\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # Observation space:\n",
    "        # [free_doctors, doctor_timers..., max_wait_red, max_wait_yellow, max_wait_green,\n",
    "        #  len_red, len_yellow, len_green, total_queue_length]\n",
    "        obs_low = np.zeros(11, dtype=np.float32)\n",
    "\n",
    "        obs_high = np.array(\n",
    "            [self.num_doctors] +         # number of doctors\n",
    "            [200] * self.num_doctors +   # service times\n",
    "            [200, 200, 200] +            # max wait red/yellow/green\n",
    "            [30, 30, 30, 30],            # queue lengths + total queue length\n",
    "            dtype=np.float32)\n",
    "\n",
    "        self.observation_space = spaces.Box(low=obs_low, high=obs_high, dtype=np.float32)\n",
    "\n",
    "\n",
    "        \n",
    "        # Actions: RED=0, YELLOW=1, GREEN=2\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # Queues\n",
    "        self.red_queue = []\n",
    "        self.yellow_queue = []\n",
    "        self.green_queue = []\n",
    "\n",
    "        # Doctors timers\n",
    "        self.doctor_timers = np.zeros(self.num_doctors)\n",
    "\n",
    "        # Step counter\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Coefficients for reward\n",
    "        self.C = {\"red\": 10.0, \"yellow\": 1.0, \"green\": 0.2}\n",
    "\n",
    "        # Max wait thresholds for critical penalty\n",
    "        self.thresholds = {\"red\": 5, \"yellow\": 15, \"green\": 30}\n",
    "        self.critical_penalty_values = {\"red\": 100, \"yellow\": 20, \"green\": 5}\n",
    "        self.critical_penalty = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "\n",
    "        # Service time ranges (minutes)\n",
    "        self.service_ranges = {\n",
    "            \"red\": (8, 15),\n",
    "            \"yellow\": (4, 8),\n",
    "            \"green\": (2, 3)\n",
    "        }\n",
    "\n",
    "        # Arrival rates per minute\n",
    "        self.arrival_lambda = {\"red\": 3, \"yellow\": 2, \"green\": 1}\n",
    "\n",
    "        # Maximum total queue length\n",
    "        self.max_queue_length = 30\n",
    "\n",
    "    # -------------------------------\n",
    "    # Reset environment\n",
    "    # -------------------------------\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.red_queue = []\n",
    "        self.yellow_queue = []\n",
    "        self.green_queue = []\n",
    "        self.doctor_timers[:] = 0\n",
    "        self.current_step = 0\n",
    "        self.critical_penalty = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    # -------------------------------\n",
    "    # Observation\n",
    "    # -------------------------------\n",
    "    def _get_obs(self):\n",
    "        total_queue = len(self.red_queue) + len(self.yellow_queue) + len(self.green_queue)\n",
    "        obs = np.array([\n",
    "            np.sum(self.doctor_timers == 0),          # free doctors\n",
    "            *self.doctor_timers,                       # remaining service times\n",
    "            max(self.red_queue) if self.red_queue else 0,\n",
    "            max(self.yellow_queue) if self.yellow_queue else 0,\n",
    "            max(self.green_queue) if self.green_queue else 0,\n",
    "            len(self.red_queue),\n",
    "            len(self.yellow_queue),\n",
    "            len(self.green_queue),\n",
    "            total_queue\n",
    "        ], dtype=np.float32)\n",
    "        return obs\n",
    "\n",
    "    # -------------------------------\n",
    "    # Sample service time\n",
    "    # -------------------------------\n",
    "    def _sample_service_time(self, action):\n",
    "        queue_map = {0: \"red\", 1: \"yellow\", 2: \"green\"}\n",
    "        low, high = self.service_ranges[queue_map[action]]\n",
    "        return np.random.randint(low, high+1)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Add new arrivals\n",
    "    # -------------------------------\n",
    "    def _add_arrivals(self, service_time):\n",
    "        # Poisson arrivals scaled by service time\n",
    "        new_red = np.random.poisson(self.arrival_lambda[\"red\"] * service_time)\n",
    "        new_yellow = np.random.poisson(self.arrival_lambda[\"yellow\"] * service_time)\n",
    "        new_green = np.random.poisson(self.arrival_lambda[\"green\"] * service_time)\n",
    "\n",
    "        # Total queue length\n",
    "        total_current = len(self.red_queue) + len(self.yellow_queue) + len(self.green_queue)\n",
    "        total_new = new_red + new_yellow + new_green\n",
    "        available_space = self.max_queue_length - total_current\n",
    "\n",
    "        if total_new > available_space:\n",
    "            # Scale down proportionally\n",
    "            factor = available_space / total_new\n",
    "            new_red = int(new_red * factor)\n",
    "            new_yellow = int(new_yellow * factor)\n",
    "            new_green = int(new_green * factor)\n",
    "\n",
    "        self.red_queue.extend([0]*new_red)\n",
    "        self.yellow_queue.extend([0]*new_yellow)\n",
    "        self.green_queue.extend([0]*new_green)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step\n",
    "    # -------------------------------\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Find first free doctor\n",
    "        free_doctors = np.where(self.doctor_timers == 0)[0]\n",
    "        if len(free_doctors) == 0:\n",
    "            # Advance by min timer to free a doctor\n",
    "            min_timer = min([t for t in self.doctor_timers if t > 0])\n",
    "            self.doctor_timers = np.maximum(0, self.doctor_timers - min_timer)\n",
    "            free_doctors = np.where(self.doctor_timers == 0)[0]\n",
    "\n",
    "        doctor = free_doctors[0]\n",
    "\n",
    "        # Map action to queue\n",
    "        queue_map = {0: self.red_queue, 1: self.yellow_queue, 2: self.green_queue}\n",
    "        queue_name_map = {0: \"red\", 1: \"yellow\", 2: \"green\"}\n",
    "        queue = queue_map[action]\n",
    "        cat_name = queue_name_map[action]\n",
    "\n",
    "        # If queue empty, reward = 0\n",
    "        if len(queue) == 0:\n",
    "            reward = 0\n",
    "            service_time = 0\n",
    "        else:\n",
    "            # Pop first patient\n",
    "            wait_time = queue.pop(0)\n",
    "            # Sample service time\n",
    "            service_time = self._sample_service_time(action)\n",
    "            self.doctor_timers[doctor] = service_time\n",
    "\n",
    "            # Increase waiting time for other patients\n",
    "            self.red_queue = [w + service_time for w in self.red_queue]\n",
    "            self.yellow_queue = [w + service_time for w in self.yellow_queue]\n",
    "            self.green_queue = [w + service_time for w in self.green_queue]\n",
    "\n",
    "            # Reduce timers of other doctors\n",
    "            for i in range(self.num_doctors):\n",
    "                if i != doctor:\n",
    "                    self.doctor_timers[i] = max(0, self.doctor_timers[i] - service_time)\n",
    "\n",
    "        # Add new arrivals\n",
    "        self._add_arrivals(service_time)\n",
    "\n",
    "        # -------------------------------\n",
    "        # Reward calculation\n",
    "        # -------------------------------\n",
    "        MaxWait_Red = max(self.red_queue) if self.red_queue else 0\n",
    "        MaxWait_Yellow = max(self.yellow_queue) if self.yellow_queue else 0\n",
    "        MaxWait_Green = max(self.green_queue) if self.green_queue else 0\n",
    "\n",
    "        reward = 10 - (self.C[\"red\"] * MaxWait_Red + self.C[\"yellow\"] * MaxWait_Yellow + self.C[\"green\"] * MaxWait_Green)\n",
    "\n",
    "        # -------------------------------\n",
    "        # Critical penalty\n",
    "        # -------------------------------\n",
    "        for q_name, q_list in [(\"red\", self.red_queue), (\"yellow\", self.yellow_queue), (\"green\", self.green_queue)]:\n",
    "            if any(w > self.thresholds[q_name] for w in q_list):\n",
    "                self.critical_penalty[q_name] += self.critical_penalty_values[q_name]\n",
    "\n",
    "        reward -= sum(self.critical_penalty.values())\n",
    "\n",
    "        # Truncated if max steps reached\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "\n",
    "        return self._get_obs(), reward, False, truncated, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843f41fe-ecf7-49a5-a34f-2a79a884e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1212     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 400      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.62     |\n",
      "|    n_updates        | 74       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1106     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 800      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1065     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1051     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.47e-06 |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1036     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.18e-10 |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 988      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000871 |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 943      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.59e-08 |\n",
      "|    n_updates        | 674      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 917      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.062    |\n",
      "|    n_updates        | 774      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.49e-06 |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.13e-11 |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.06e-07 |\n",
      "|    n_updates        | 1074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.6e-09  |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 848      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 5200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0365   |\n",
      "|    n_updates        | 1274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 5600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.77e-07 |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.67e-11 |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000303 |\n",
      "|    n_updates        | 1574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 822      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 6800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.23e-09 |\n",
      "|    n_updates        | 1674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 817      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 811      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 7600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.44e-08 |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 793      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.05e-11 |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 785      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000214 |\n",
      "|    n_updates        | 2074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 781      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 8800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.7e-09  |\n",
      "|    n_updates        | 2174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 9200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 2274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 777      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.14e-07 |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 772      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.09e-11 |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 767      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 10400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.71e-05 |\n",
      "|    n_updates        | 2574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 765      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 10800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.3e-08  |\n",
      "|    n_updates        | 2674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 761      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 11200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 2774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 757      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 11600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.26e-06 |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 753      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.87e-11 |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 749      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 12400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.08e-05 |\n",
      "|    n_updates        | 3074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 747      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 12800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.44e-10 |\n",
      "|    n_updates        | 3174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 743      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 13200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 3274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 739      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 13600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.6e-07  |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 736      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.82e-12 |\n",
      "|    n_updates        | 3474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.62e-05 |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 14800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.6e-10  |\n",
      "|    n_updates        | 3674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 15200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 3774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 732      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 15600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.02e-07 |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 735      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2e-11    |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 737      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 16400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.79e-05 |\n",
      "|    n_updates        | 4074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 739      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.74e-09 |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 742      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 17200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 4274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 744      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 17600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.32e-06 |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 745      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.23e-11 |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 746      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 18400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.28e-05 |\n",
      "|    n_updates        | 4574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 746      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 18800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.95e-08 |\n",
      "|    n_updates        | 4674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 744      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00741  |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 742      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 19600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.09e-07 |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 742      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.46e-11 |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 740      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 20400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.83e-05 |\n",
      "|    n_updates        | 5074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 739      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 20800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.46e-11 |\n",
      "|    n_updates        | 5174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 738      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 21200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 5274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 736      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.08e-07 |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 732      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4e-11    |\n",
      "|    n_updates        | 5474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 22400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.87e-05 |\n",
      "|    n_updates        | 5574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 22800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.64e-09 |\n",
      "|    n_updates        | 5674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 23200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 5774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 23600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.14e-07 |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.28e-11 |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 724      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 24400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.41e-05 |\n",
      "|    n_updates        | 6074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 24800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.46e-10 |\n",
      "|    n_updates        | 6174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 25200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 6274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 25600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.07e-07 |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 724      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.18e-10 |\n",
      "|    n_updates        | 6474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.68e-05 |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 26800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.31e-09 |\n",
      "|    n_updates        | 6674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 724      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 27200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 6774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 27600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.41e-08 |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0        |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 28400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.98e-05 |\n",
      "|    n_updates        | 7074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.53e-10 |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 29200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000181 |\n",
      "|    n_updates        | 7274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 718      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 29600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.91e-08 |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.02e-10 |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 30400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.69e-05 |\n",
      "|    n_updates        | 7574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 30800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.01e-09 |\n",
      "|    n_updates        | 7674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00595  |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 31600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.36e-08 |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 715      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.38e-10 |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 715      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 32400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.81e-05 |\n",
      "|    n_updates        | 8074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 32800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.12e-09 |\n",
      "|    n_updates        | 8174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 33200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 8274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.81e-07 |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 718      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.37e-10 |\n",
      "|    n_updates        | 8474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 719      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 34400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.37e-06 |\n",
      "|    n_updates        | 8574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 34800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.55e-09 |\n",
      "|    n_updates        | 8674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 35200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 8774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 35600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.46e-08 |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.36e-10 |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 36400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.16e-06 |\n",
      "|    n_updates        | 9074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 36800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.99e-09 |\n",
      "|    n_updates        | 9174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 37200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 9274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 719      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 37600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.69e-08 |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.76e-10 |\n",
      "|    n_updates        | 9474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.54e-06 |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 38800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.57e-10 |\n",
      "|    n_updates        | 9674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 39200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 9774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 39600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.62e-07 |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.69e-10 |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 40400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.56e-06 |\n",
      "|    n_updates        | 10074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.93e-10 |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 724      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 41200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000174 |\n",
      "|    n_updates        | 10274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 41600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.53e-09 |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0        |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 42400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.62e-05 |\n",
      "|    n_updates        | 10574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 42800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.77e-10 |\n",
      "|    n_updates        | 10674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000317 |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 43600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.46e-07 |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.89e-10 |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 44400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.31e-05 |\n",
      "|    n_updates        | 11074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 44800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.58e-10 |\n",
      "|    n_updates        | 11174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000184 |\n",
      "|    n_updates        | 11274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.19e-07 |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.8e-10  |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 46400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.31e-05 |\n",
      "|    n_updates        | 11574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 46800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.31e-10 |\n",
      "|    n_updates        | 11674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 47200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 11774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 47600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.93e-08 |\n",
      "|    n_updates        | 11874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.35e-10 |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 48400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.89e-05 |\n",
      "|    n_updates        | 12074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 48800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.18e-09 |\n",
      "|    n_updates        | 12174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 49200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 12274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 49600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.8e-07  |\n",
      "|    n_updates        | 12374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.08e-10 |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "Model saved to models/dqn_hospital_sb3.zip\n",
      "Mean reward: 1000.00  0.00\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../env\")  # to read hospital_env.py\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ------------------------------\n",
    "# Set seeds for reproducibility\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- Create wrapped environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env.reset(seed=SEED)   # seed the environment here\n",
    "    env = Monitor(env)      # important for SB3 logging\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Create DQN agent ---\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",       # Fully connected NN\n",
    "    env,\n",
    "    learning_rate=5e-4,\n",
    "    gamma=0.95,\n",
    "    batch_size=64,\n",
    "    buffer_size=50000,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.1,\n",
    "    exploration_fraction=0.1,   # epsilon decay\n",
    "    target_update_interval=1000,\n",
    "    verbose=1,\n",
    "    seed=SEED                  # seed SB3 agent\n",
    ")\n",
    "\n",
    "# --- Train agent ---\n",
    "model.learn(total_timesteps=50000)\n",
    "\n",
    "# --- Save trained model ---\n",
    "model.save(\"../models/dqn_hospital_sb3\")\n",
    "print(\"Model saved to models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=50)\n",
    "print(f\"Mean reward: {mean_reward:.2f}  {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d939bc11-d22b-4827-bd11-83ce22cc1d0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have passed a tuple to the predict() function instead of a Numpy array or a Dict. You are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) vs `obs = vec_env.reset()` (SB3 VecEnv). See related issue https://github.com/DLR-RM/stable-baselines3/issues/1694 and documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m total_reward = \u001b[32m0\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     action, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     obs, reward, done, info = env.step(action)\n\u001b[32m     27\u001b[39m     total_reward += reward\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:255\u001b[39m, in \u001b[36mDQN.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    253\u001b[39m         action = np.array(\u001b[38;5;28mself\u001b[39m.action_space.sample())\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     action, state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m action, state\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl_env\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:357\u001b[39m, in \u001b[36mBasePolicy.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;66;03m# Check for common mistake that the user does not mix Gym/VecEnv API\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m# Tuple obs are not supported by SB3, so we can safely do that check\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[32m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvs `obs = vec_env.reset()` (SB3 VecEnv). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee related issue https://github.com/DLR-RM/stable-baselines3/issues/1694 \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    365\u001b[39m obs_tensor, vectorized_env = \u001b[38;5;28mself\u001b[39m.obs_to_tensor(observation)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n",
      "\u001b[31mValueError\u001b[39m: You have passed a tuple to the predict() function instead of a Numpy array or a Dict. You are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) vs `obs = vec_env.reset()` (SB3 VecEnv). See related issue https://github.com/DLR-RM/stable-baselines3/issues/1694 and documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api"
     ]
    }
   ],
   "source": [
    "from hospital_env import HospitalEnv\n",
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "\n",
    "# Load trained agent\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "env = HospitalEnv()\n",
    "\n",
    "# Metrics storage\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # Record wait times for fairness & thresholds\n",
    "        last_waits = getattr(env, \"last_served_wait_times\", {})  # assume you save these in env\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# Compute metrics\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits)\n",
    "avg_wait_yellow = np.mean(yellow_waits)\n",
    "avg_wait_green = np.mean(green_waits)\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = 1 - (max(avg_wait_red, avg_wait_yellow, avg_wait_green) - min(avg_wait_red, avg_wait_yellow, avg_wait_green)) / max(avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "\n",
    "# Print results\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats:\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e59109a-10c0-4120-b67d-8ab1c5ef3079",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Predict action\u001b[39;00m\n\u001b[32m     34\u001b[39m     action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     obs, reward, terminated, truncated, info = eval_env.step(action)\n\u001b[32m     36\u001b[39m     done = terminated[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m truncated[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# single env\u001b[39;00m\n\u001b[32m     37\u001b[39m     total_reward += reward[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "from hospital_env import HospitalEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import numpy as np\n",
    "\n",
    "# --- Load trained agent ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# --- Wrap the environment for SB3 ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Metrics storage ---\n",
    "episodes = 50  # more episodes to get stable metrics\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served = yellow_served = green_served = 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "# --- Evaluate agent ---\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()  # returns np.array\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated[0] or truncated[0]  # single env\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # Access underlying HospitalEnv\n",
    "        env0 = eval_env.envs[0]\n",
    "\n",
    "        # Record queue lengths for stability\n",
    "        queue_lengths[\"red\"].append(len(env0.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env0.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env0.green_queue))\n",
    "\n",
    "        # Track wait times per patient served\n",
    "        if hasattr(env0, \"last_served_wait_times\"):  # if you implement this in env\n",
    "            last_waits = env0.last_served_wait_times\n",
    "            for cat, wait in last_waits.items():\n",
    "                if cat == \"red\":\n",
    "                    red_waits.append(wait)\n",
    "                    red_served += 1\n",
    "                elif cat == \"yellow\":\n",
    "                    yellow_waits.append(wait)\n",
    "                    yellow_served += 1\n",
    "                elif cat == \"green\":\n",
    "                    green_waits.append(wait)\n",
    "                    green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "\n",
    "# 1. Average episode reward\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "\n",
    "# 2. Convergence speed (std across episodes can indicate stability)\n",
    "reward_std = np.std(rewards_per_episode)\n",
    "\n",
    "# 3. Average waiting time per triage category\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "# 4. Percentage within clinical thresholds\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "# 5. Queue stability measures (avg and max)\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "# 6. Fairness metric\n",
    "waits = [avg_wait_red, avg_wait_yellow, avg_wait_green]\n",
    "fairness = 1 - (max(waits) - min(waits)) / max(waits) if max(waits) > 0 else 1.0\n",
    "\n",
    "# --- Print metrics ---\n",
    "print(\"=== RL Agent Evaluation Metrics ===\")\n",
    "print(f\"Average episode reward: {avg_reward:.2f}  {reward_std:.2f}\")\n",
    "print(f\"Average wait times (Red, Yellow, Green): {avg_wait_red:.2f}, {avg_wait_yellow:.2f}, {avg_wait_green:.2f}\")\n",
    "print(f\"Percentage served within thresholds (Red, Yellow, Green): {pct_red_within:.1f}%, {pct_yellow_within:.1f}%, {pct_green_within:.1f}%\")\n",
    "print(\"Queue stats:\", queue_stats)\n",
    "print(f\"Fairness metric: {fairness:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4812ec80-55d1-4cd9-9dd9-d305429f9e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 5006.74\n",
      "Average wait times (Red, Yellow, Green): 0 0 0\n",
      "Percentage served within thresholds (Red, Yellow, Green): 0 0 0\n",
      "Queue stats (average and max lengths): {'red': {'avg': np.float64(0.0), 'max': np.int64(0)}, 'yellow': {'avg': np.float64(0.0), 'max': np.int64(0)}, 'green': {'avg': np.float64(0.0), 'max': np.int64(0)}}\n",
      "Fairness metric: 1\n"
     ]
    }
   ],
   "source": [
    "from hospital_env import HospitalEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# Load trained model\n",
    "# ------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# ------------------------\n",
    "# Wrap environment\n",
    "# ------------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# ------------------------\n",
    "# Metrics storage\n",
    "# ------------------------\n",
    "episodes = 50\n",
    "rewards_per_episode = []\n",
    "\n",
    "# Track waiting times per triage category\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "\n",
    "# Track patients served per triage category\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "\n",
    "# Track queue lengths\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "\n",
    "# Clinical target thresholds (minutes)\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "# ------------------------\n",
    "# Evaluation loop\n",
    "# ------------------------\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    # Reset per-episode queues in environment (if needed)\n",
    "    eval_env.envs[0].red_queue = []\n",
    "    eval_env.envs[0].yellow_queue = []\n",
    "    eval_env.envs[0].green_queue = []\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done_array, info = eval_env.step(action)\n",
    "        done = done_array[0]  # single environment\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(eval_env.envs[0].red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(eval_env.envs[0].yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(eval_env.envs[0].green_queue))\n",
    "\n",
    "        # Record served patients and their wait times\n",
    "        last_waits = getattr(eval_env.envs[0], \"last_served_wait_times\", {})\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# ------------------------\n",
    "# Compute metrics\n",
    "# ------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "# Fairness: 1 - normalized difference between max & min average wait times\n",
    "max_wait = max(avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "min_wait = min(avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "fairness = 1 - ((max_wait - min_wait) / max_wait) if max_wait > 0 else 1\n",
    "\n",
    "# ------------------------\n",
    "# Print results\n",
    "# ------------------------\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad5c0dee-6b66-4c7e-8a4f-e4107376c081",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# --- Take step ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m obs, reward, terminated, truncated, info = eval_env.step(action)\n\u001b[32m     40\u001b[39m done = terminated[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m truncated[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# VecEnv returns arrays\u001b[39;00m\n\u001b[32m     41\u001b[39m total_reward += reward[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "sys.path.append(\"../env\")  # path to your HospitalEnv\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# --- Create wrapped environment for evaluation ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 requires Monitor for VecEnv\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# --- Metrics storage ---\n",
    "episodes = 10\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()  # VecEnv returns array only\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # --- Predict action ---\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # --- Take step ---\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated[0] or truncated[0]  # VecEnv returns arrays\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # --- Track queue lengths ---\n",
    "        env_instance = eval_env.envs[0]  # get underlying env\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        # --- Track wait times for fairness & thresholds ---\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {})\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served > 0 else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served > 0 else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served > 0 else 0\n",
    "\n",
    "queue_stats = {\n",
    "    cat: {\"avg\": np.mean(qs) if qs else 0, \"max\": np.max(qs) if qs else 0}\n",
    "    for cat, qs in queue_lengths.items()\n",
    "}\n",
    "\n",
    "# Fairness: 1 - normalized difference between max & min avg wait times\n",
    "waits = [avg_wait_red, avg_wait_yellow, avg_wait_green]\n",
    "fairness = 1 - (max(waits) - min(waits)) / max(waits) if max(waits) > 0 else 1\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc17263b-c5ae-46ee-802b-a72f8dea4e82",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Monitor' object has no attribute 'red_queue'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m env_instance = eval_env.envs[\u001b[32m0\u001b[39m]\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# --- Queue stats ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m queue_lengths[\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m].append(\u001b[38;5;28mlen\u001b[39m(\u001b[43menv_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mred_queue\u001b[49m))\n\u001b[32m     47\u001b[39m queue_lengths[\u001b[33m\"\u001b[39m\u001b[33myellow\u001b[39m\u001b[33m\"\u001b[39m].append(\u001b[38;5;28mlen\u001b[39m(env_instance.yellow_queue))\n\u001b[32m     48\u001b[39m queue_lengths[\u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m].append(\u001b[38;5;28mlen\u001b[39m(env_instance.green_queue))\n",
      "\u001b[31mAttributeError\u001b[39m: 'Monitor' object has no attribute 'red_queue'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# --- Wrap the environment for SB3 ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # required for SB3 logging\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\", env=eval_env)\n",
    "\n",
    "# --- Metrics storage ---\n",
    "episodes = 10\n",
    "rewards_per_episode = []\n",
    "\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "fairness_list = []\n",
    "\n",
    "# --- Evaluation loop ---\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done_array, info = eval_env.step(action)\n",
    "        done = done_array[0]      # Single env\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # Access underlying env to get metrics\n",
    "        env_instance = eval_env.envs[0]\n",
    "\n",
    "        # --- Queue stats ---\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        # --- Wait times for last served patient ---\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {})\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "        # --- Fairness metric per step ---\n",
    "        if red_waits and yellow_waits and green_waits:\n",
    "            max_wait = max(np.mean(red_waits), np.mean(yellow_waits), np.mean(green_waits))\n",
    "            min_wait = min(np.mean(red_waits), np.mean(yellow_waits), np.mean(green_waits))\n",
    "            fairness_list.append(1 - (max_wait - min_wait) / max_wait)\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute final metrics ---\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs) if qs else 0, \"max\": np.max(qs) if qs else 0} \n",
    "               for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = np.mean(fairness_list) if fairness_list else 1\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94abbc4d-541b-4faf-8c8a-eaab91f69096",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# --- Take step ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m obs, reward, terminated, truncated, info = eval_env.step(action)\n\u001b[32m     37\u001b[39m done = terminated[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m truncated[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# VecEnv returns arrays\u001b[39;00m\n\u001b[32m     38\u001b[39m total_reward += reward[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# --- Create wrapped environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # SB3 requires Monitor\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Load trained agent ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\", env=eval_env)\n",
    "\n",
    "# --- Metrics storage ---\n",
    "episodes = 10\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # --- Predict action ---\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "        # --- Take step ---\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated[0] or truncated[0]  # VecEnv returns arrays\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # --- Access underlying environment for queue metrics ---\n",
    "        env_instance = eval_env.envs[0].envs[0].unwrapped  # DummyVecEnv -> Monitor -> HospitalEnv\n",
    "\n",
    "        # Queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        # Wait times from last served patient\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {})\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served > 0 else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served > 0 else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served > 0 else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs) if qs else 0, \"max\": np.max(qs) if qs else 0} \n",
    "               for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = 1 - (max(avg_wait_red, avg_wait_yellow, avg_wait_green) - min(avg_wait_red, avg_wait_yellow, avg_wait_green)) / max(avg_wait_red, avg_wait_yellow, avg_wait_green) if max(avg_wait_red, avg_wait_yellow, avg_wait_green) > 0 else 1\n",
    "\n",
    "# --- Print metrics ---\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c346e7de-7ec0-476e-a309-a8565273e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 5035.2\n",
      "Average wait times (Red, Yellow, Green): 8.5165 0.0 1.7735\n",
      "Percentage served within thresholds (Red, Yellow, Green): 99.55 100.0 99.55\n",
      "Queue stats (average and max lengths): {'red': {'avg': np.float64(9.098), 'max': np.int64(34)}, 'yellow': {'avg': np.float64(194.8945), 'max': np.int64(416)}, 'green': {'avg': np.float64(93.3735), 'max': np.int64(223)}}\n",
      "Fairness metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import sys\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "\n",
    "# --- Wrapped environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\", env=eval_env)\n",
    "\n",
    "# --- Metrics ---\n",
    "episodes = 10\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "        # --- SB3 VecEnv returns 4 values ---\n",
    "        obs, rewards, dones, infos = eval_env.step(action)\n",
    "        done = dones[0]\n",
    "        total_reward += rewards[0]\n",
    "\n",
    "        # Access underlying HospitalEnv\n",
    "        env_instance = eval_env.envs[0].env\n",
    "\n",
    "        # Queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        # Last served wait times\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {})\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs) if qs else 0, \"max\": np.max(qs) if qs else 0}\n",
    "               for cat, qs in queue_lengths.items()}\n",
    "\n",
    "fairness = 1 - (max(avg_wait_red, avg_wait_yellow, avg_wait_green) -\n",
    "                min(avg_wait_red, avg_wait_yellow, avg_wait_green)) / max(avg_wait_red, avg_wait_yellow, avg_wait_green) \\\n",
    "                if max(avg_wait_red, avg_wait_yellow, avg_wait_green) > 0 else 1\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63cbc0be-2acc-4662-a857-5c5faff43588",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Take step\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m obs, reward, terminated, truncated, info = eval_env.step(action)\n\u001b[32m     49\u001b[39m done = terminated[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m truncated[\u001b[32m0\u001b[39m]\n\u001b[32m     50\u001b[39m total_reward += reward[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# -----------------------\n",
    "# Create environment\n",
    "# -----------------------\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)  # Needed for SB3\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# -----------------------\n",
    "# Load trained model\n",
    "# -----------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# -----------------------\n",
    "# Metrics storage\n",
    "# -----------------------\n",
    "episodes = 10\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "all_rewards = []\n",
    "all_waits = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "served_within_threshold = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "fairness_counts = []\n",
    "\n",
    "# -----------------------\n",
    "# Run episodes\n",
    "# -----------------------\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    green_fairness_window = []\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Take step\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated[0] or truncated[0]\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # Get the actual environment instance to access queues and last served waits\n",
    "        env_instance = eval_env.envs[0].env  # unwrap Monitor\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {\"red\":0,\"yellow\":0,\"green\":0})\n",
    "        \n",
    "        # Record waits\n",
    "        for cat in [\"red\", \"yellow\", \"green\"]:\n",
    "            if cat in last_waits:\n",
    "                all_waits[cat].append(last_waits[cat])\n",
    "                if last_waits[cat] <= threshold_times[cat]:\n",
    "                    served_within_threshold[cat] += 1\n",
    "\n",
    "        # Record queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        # Track green fairness (was a green patient served recently?)\n",
    "        green_fairness_window.append(int(action[0] == 2))\n",
    "        if len(green_fairness_window) > 5:\n",
    "            green_fairness_window.pop(0)\n",
    "        fairness_counts.append(1 if sum(green_fairness_window) > 0 else 0)\n",
    "\n",
    "    all_rewards.append(total_reward)\n",
    "\n",
    "# -----------------------\n",
    "# Compute metrics\n",
    "# -----------------------\n",
    "avg_reward = np.mean(all_rewards)\n",
    "avg_waits = {cat: np.mean(all_waits[cat]) for cat in [\"red\",\"yellow\",\"green\"]}\n",
    "pct_within = {cat: 100 * served_within_threshold[cat] / len(all_waits[cat]) if all_waits[cat] else 0 \n",
    "              for cat in [\"red\",\"yellow\",\"green\"]}\n",
    "queue_stats = {cat: {\"avg\": np.mean(queue_lengths[cat]), \"max\": np.max(queue_lengths[cat])} \n",
    "               for cat in [\"red\",\"yellow\",\"green\"]}\n",
    "fairness_metric = np.mean(fairness_counts)\n",
    "\n",
    "# -----------------------\n",
    "# Print results\n",
    "# -----------------------\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_waits[\"red\"], avg_waits[\"yellow\"], avg_waits[\"green\"])\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_within[\"red\"], pct_within[\"yellow\"], pct_within[\"green\"])\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Fairness metric (green patient policy):\", fairness_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f5c50d-19ca-40bd-bbbe-b60273b68429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 5035.2\n",
      "Average wait times (Red, Yellow, Green): 8.5165 0.0 1.7735\n",
      "Percentage served within thresholds (Red, Yellow, Green): 99.55 100.0 99.55\n",
      "Queue stats (average and max lengths): {'red': {'avg': np.float64(9.098), 'max': np.int64(34)}, 'yellow': {'avg': np.float64(194.8945), 'max': np.int64(416)}, 'green': {'avg': np.float64(93.3735), 'max': np.int64(223)}}\n",
      "Green fairness metric: 0.1745\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# --- Create wrapped evaluation environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# --- Metrics storage ---\n",
    "episodes = 10\n",
    "\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "green_fair_actions = []\n",
    "\n",
    "# --- Evaluation loop ---\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        # Step in vectorized env (4 outputs)\n",
    "        obs, reward, done_array, info = eval_env.step(action)\n",
    "        done = done_array[0]  # single environment\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # Access the inner env to read queues and last served waits\n",
    "        env_instance = eval_env.envs[0].env  # unwrap Monitor\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {})\n",
    "        for cat, w in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(w)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(w)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(w)\n",
    "                green_served += 1\n",
    "\n",
    "        # Track fairness: was green served at least once in last 5 actions?\n",
    "        if 2 in env_instance.last_5_actions:\n",
    "            green_fair_actions.append(1)\n",
    "        else:\n",
    "            green_fair_actions.append(0)\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "# Fairness metric for green patients: proportion of steps where green was served in last 5 actions\n",
    "fairness = np.mean(green_fair_actions) if green_fair_actions else 0\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Green fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0254dbdc-7875-45e0-ad91-c5858748b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 901.3\n",
      "Average wait times (Red, Yellow, Green): 3.55 0.0 6.66\n",
      "Percentage served within thresholds (Red, Yellow, Green): 100.0 100.0 100.0\n",
      "Queue stats (average and max lengths): {'red': {'avg': np.float64(3.736666666666667), 'max': np.int64(14)}, 'yellow': {'avg': np.float64(28.546666666666667), 'max': np.int64(68)}, 'green': {'avg': np.float64(25.8), 'max': np.int64(66)}}\n",
      "Green fairness metric: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../env\")  \n",
    "from hospital_env import HospitalEnv\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from hospital_env import HospitalEnv\n",
    "\n",
    "# --- Create wrapped evaluation environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3\", env=eval_env)\n",
    "\n",
    "# --- Metrics storage ---\n",
    "episodes = 10\n",
    "\n",
    "rewards_per_episode = []\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "green_fair_actions = []\n",
    "\n",
    "# --- Evaluation loop ---\n",
    "for ep in range(episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        # Step in vectorized env (4 outputs)\n",
    "        obs, reward, done_array, info = eval_env.step(action)\n",
    "        done = done_array[0]  # single environment\n",
    "        total_reward += reward[0]\n",
    "\n",
    "        # Access the inner env to read queues and last served waits\n",
    "        env_instance = eval_env.envs[0].env  # unwrap Monitor\n",
    "        queue_lengths[\"red\"].append(len(env_instance.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env_instance.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env_instance.green_queue))\n",
    "\n",
    "        last_waits = getattr(env_instance, \"last_served_wait_times\", {})\n",
    "        for cat, w in last_waits.items():\n",
    "            if cat == \"red\":\n",
    "                red_waits.append(w)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\":\n",
    "                yellow_waits.append(w)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\":\n",
    "                green_waits.append(w)\n",
    "                green_served += 1\n",
    "\n",
    "        # Track fairness: was green served at least once in last 5 actions?\n",
    "        if 2 in env_instance.last_5_actions:\n",
    "            green_fair_actions.append(1)\n",
    "        else:\n",
    "            green_fair_actions.append(0)\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "# Fairness metric for green patients: proportion of steps where green was served in last 5 actions\n",
    "fairness = np.mean(green_fair_actions) if green_fair_actions else 0\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Green fairness metric:\", fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974a5a4b-8ca9-4f3a-be31-a5507718e0cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m     37\u001b[39m     action, _ = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     obs, reward, terminated, truncated, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m     40\u001b[39m     total_reward += reward\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\RL_Project_New\\training\\../env\\hospital_env.py:133\u001b[39m, in \u001b[36mHospitalEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Map action to queue\u001b[39;00m\n\u001b[32m    130\u001b[39m queue_map = {\u001b[32m0\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.red_queue),\n\u001b[32m    131\u001b[39m              \u001b[32m1\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33myellow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.yellow_queue),\n\u001b[32m    132\u001b[39m              \u001b[32m2\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.green_queue)}\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m cat_name, queue = \u001b[43mqueue_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# If queue empty  0 reward\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queue) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from hospital_env import HospitalEnv  # Make sure this is in your path\n",
    "\n",
    "# -----------------------------\n",
    "# Load trained model and env\n",
    "# -----------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "env = HospitalEnv()\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "episodes = 10\n",
    "rewards_per_episode = []\n",
    "\n",
    "all_wait_times = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "served_within_thresholds = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "total_served = {\"red\": 0, \"yellow\": 0, \"green\": 0}\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "green_fairness_actions = []\n",
    "\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation loop\n",
    "# -----------------------------\n",
    "for ep in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "\n",
    "        # -----------------------------\n",
    "        # Track queue lengths at each step\n",
    "        # -----------------------------\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Track last served wait times\n",
    "        # -----------------------------\n",
    "        for cat in [\"red\", \"yellow\", \"green\"]:\n",
    "            wait = env.last_served_wait_times.get(cat, 0)\n",
    "            if wait > 0:\n",
    "                all_wait_times[cat].append(wait)\n",
    "                total_served[cat] += 1\n",
    "                if wait <= threshold_times[cat]:\n",
    "                    served_within_thresholds[cat] += 1\n",
    "\n",
    "        # -----------------------------\n",
    "        # Track green fairness (was green served in last 5 actions)\n",
    "        # -----------------------------\n",
    "        green_fairness_actions.append(2 in env.last_5_actions)\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# -----------------------------\n",
    "# Compute metrics\n",
    "# -----------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait = {cat: np.mean(all_wait_times[cat]) if all_wait_times[cat] else 0 for cat in all_wait_times}\n",
    "pct_within = {cat: (served_within_thresholds[cat] / total_served[cat] * 100) if total_served[cat] else 0 for cat in total_served}\n",
    "queue_stats = {cat: {\"avg\": np.mean(queue_lengths[cat]), \"max\": np.max(queue_lengths[cat])} for cat in queue_lengths}\n",
    "green_fairness = np.mean(green_fairness_actions)\n",
    "\n",
    "# -----------------------------\n",
    "# Print metrics\n",
    "# -----------------------------\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait[\"red\"], avg_wait[\"yellow\"], avg_wait[\"green\"])\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_within[\"red\"], pct_within[\"yellow\"], pct_within[\"green\"])\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Green fairness metric:\", green_fairness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dd343c-ec3e-4e36-b1ef-c3cee06a40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 905.1\n",
      "Average wait times (Red, Yellow, Green): 4.154121863799283 7.6 9.835390946502057\n",
      "Percentage served within thresholds (Red, Yellow, Green): 100.0 100.0 100.0\n",
      "Queue stats (average and max lengths): {'red': {'avg': np.float64(3.89), 'max': np.int64(11)}, 'yellow': {'avg': np.float64(30.386666666666667), 'max': np.int64(80)}, 'green': {'avg': np.float64(27.89666666666667), 'max': np.int64(65)}}\n",
      "Green fairness metric: 0.5966666666666667\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from hospital_env import HospitalEnv  # make sure hospital_env.py is in the same folder\n",
    "\n",
    "# -------------------------\n",
    "# Load trained agent\n",
    "# -------------------------\n",
    "model = DQN.load(\"../models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# -------------------------\n",
    "# Create environment\n",
    "# -------------------------\n",
    "env = HospitalEnv()\n",
    "\n",
    "# -------------------------\n",
    "# Metrics storage\n",
    "# -------------------------\n",
    "episodes = 10\n",
    "rewards_per_episode = []\n",
    "\n",
    "red_waits, yellow_waits, green_waits = [], [], []\n",
    "red_served, yellow_served, green_served = 0, 0, 0\n",
    "\n",
    "queue_lengths = {\"red\": [], \"yellow\": [], \"green\": []}\n",
    "threshold_times = {\"red\": 30, \"yellow\": 60, \"green\": 120}\n",
    "\n",
    "green_fairness_counts = 0  # counts how often green appears in last 5 actions\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation loop\n",
    "# -------------------------\n",
    "for ep in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        action = int(action)  # <-- convert to int\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "\n",
    "        # Track queue lengths\n",
    "        queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "        queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "        queue_lengths[\"green\"].append(len(env.green_queue))\n",
    "\n",
    "        # Track last served wait times\n",
    "        last_waits = env.last_served_wait_times\n",
    "        for cat, wait in last_waits.items():\n",
    "            if cat == \"red\" and wait > 0:\n",
    "                red_waits.append(wait)\n",
    "                red_served += 1\n",
    "            elif cat == \"yellow\" and wait > 0:\n",
    "                yellow_waits.append(wait)\n",
    "                yellow_served += 1\n",
    "            elif cat == \"green\" and wait > 0:\n",
    "                green_waits.append(wait)\n",
    "                green_served += 1\n",
    "\n",
    "        # Green fairness: check if green patient was served in last 5 actions\n",
    "        if 2 in env.last_5_actions:\n",
    "            green_fairness_counts += 1\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "# -------------------------\n",
    "# Compute metrics\n",
    "# -------------------------\n",
    "avg_reward = np.mean(rewards_per_episode)\n",
    "avg_wait_red = np.mean(red_waits) if red_waits else 0\n",
    "avg_wait_yellow = np.mean(yellow_waits) if yellow_waits else 0\n",
    "avg_wait_green = np.mean(green_waits) if green_waits else 0\n",
    "\n",
    "pct_red_within = 100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / red_served if red_served else 0\n",
    "pct_yellow_within = 100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / yellow_served if yellow_served else 0\n",
    "pct_green_within = 100 * sum(w <= threshold_times[\"green\"] for w in green_waits) / green_served if green_served else 0\n",
    "\n",
    "queue_stats = {cat: {\"avg\": np.mean(qs), \"max\": np.max(qs)} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "green_fairness_metric = green_fairness_counts / (episodes * env.max_steps)  # fraction of steps where green was in last 5 actions\n",
    "\n",
    "# -------------------------\n",
    "# Print results\n",
    "# -------------------------\n",
    "print(\"Average reward per episode:\", avg_reward)\n",
    "print(\"Average wait times (Red, Yellow, Green):\", avg_wait_red, avg_wait_yellow, avg_wait_green)\n",
    "print(\"Percentage served within thresholds (Red, Yellow, Green):\", pct_red_within, pct_yellow_within, pct_green_within)\n",
    "print(\"Queue stats (average and max lengths):\", queue_stats)\n",
    "print(\"Green fairness metric:\", green_fairness_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8fc7104-8694-4dea-9dd6-569ca2c4fc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1102     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 400      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.62     |\n",
      "|    n_updates        | 74       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1067     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 800      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1041     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1025     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.47e-06 |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1016     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.18e-10 |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1010     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000871 |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 995      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.59e-08 |\n",
      "|    n_updates        | 674      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 980      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.062    |\n",
      "|    n_updates        | 774      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 972      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.49e-06 |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.13e-11 |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.06e-07 |\n",
      "|    n_updates        | 1074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 944      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.6e-09  |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 932      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 5200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0365   |\n",
      "|    n_updates        | 1274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 5600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.77e-07 |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 918      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.67e-11 |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 912      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000303 |\n",
      "|    n_updates        | 1574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.23e-09 |\n",
      "|    n_updates        | 1674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 7600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.44e-08 |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.05e-11 |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000214 |\n",
      "|    n_updates        | 2074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 8800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.7e-09  |\n",
      "|    n_updates        | 2174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 9200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 2274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.14e-07 |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.09e-11 |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 10400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.71e-05 |\n",
      "|    n_updates        | 2574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 10800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.3e-08  |\n",
      "|    n_updates        | 2674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 864      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 11200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 2774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 11600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.26e-06 |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.87e-11 |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 852      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 12400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.08e-05 |\n",
      "|    n_updates        | 3074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 849      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 12800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.44e-10 |\n",
      "|    n_updates        | 3174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 845      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 13200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 3274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 13600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.6e-07  |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.82e-12 |\n",
      "|    n_updates        | 3474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.62e-05 |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 832      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 14800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.6e-10  |\n",
      "|    n_updates        | 3674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 15200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 3774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 15600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 8.02e-07 |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2e-11    |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 16400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.79e-05 |\n",
      "|    n_updates        | 4074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.74e-09 |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 17200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 4274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 17600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.32e-06 |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.23e-11 |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 18400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.28e-05 |\n",
      "|    n_updates        | 4574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 825      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 18800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.95e-08 |\n",
      "|    n_updates        | 4674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 825      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00741  |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 19600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.09e-07 |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.46e-11 |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 827      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 20400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.83e-05 |\n",
      "|    n_updates        | 5074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 20800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.46e-11 |\n",
      "|    n_updates        | 5174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 21200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 5274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.08e-07 |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4e-11    |\n",
      "|    n_updates        | 5474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 22400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.87e-05 |\n",
      "|    n_updates        | 5574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 22800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.64e-09 |\n",
      "|    n_updates        | 5674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 23200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 5774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 23600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.14e-07 |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.28e-11 |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 24400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.41e-05 |\n",
      "|    n_updates        | 6074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 24800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.46e-10 |\n",
      "|    n_updates        | 6174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 25200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 6274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 827      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 25600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.07e-07 |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.18e-10 |\n",
      "|    n_updates        | 6474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 823      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.68e-05 |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 822      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 26800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.31e-09 |\n",
      "|    n_updates        | 6674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 27200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 6774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 27600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.41e-08 |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0        |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 28400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.98e-05 |\n",
      "|    n_updates        | 7074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.53e-10 |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 29200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000181 |\n",
      "|    n_updates        | 7274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 820      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 29600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.91e-08 |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 819      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.02e-10 |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 819      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 30400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.69e-05 |\n",
      "|    n_updates        | 7574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 820      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 30800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 7.01e-09 |\n",
      "|    n_updates        | 7674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 815      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00595  |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 813      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 31600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.36e-08 |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 811      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.38e-10 |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 809      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 32400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.81e-05 |\n",
      "|    n_updates        | 8074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 32800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.12e-09 |\n",
      "|    n_updates        | 8174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 33200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 8274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.81e-07 |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.37e-10 |\n",
      "|    n_updates        | 8474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 34400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.37e-06 |\n",
      "|    n_updates        | 8574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 34800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.55e-09 |\n",
      "|    n_updates        | 8674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 804      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 35200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 8774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 802      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 35600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.46e-08 |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 801      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.36e-10 |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 800      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 36400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.16e-06 |\n",
      "|    n_updates        | 9074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 36800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.99e-09 |\n",
      "|    n_updates        | 9174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 796      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 37200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 9274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 794      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 37600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.69e-08 |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 792      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.76e-10 |\n",
      "|    n_updates        | 9474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.54e-06 |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 38800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.57e-10 |\n",
      "|    n_updates        | 9674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 39200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 9774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 788      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 39600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.62e-07 |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 786      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.69e-10 |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 40400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.56e-06 |\n",
      "|    n_updates        | 10074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 782      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.93e-10 |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 782      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 41200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000174 |\n",
      "|    n_updates        | 10274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 41600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 9.53e-09 |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 781      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0        |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 779      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 42400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.62e-05 |\n",
      "|    n_updates        | 10574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 42800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.77e-10 |\n",
      "|    n_updates        | 10674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 776      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000317 |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 43600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.46e-07 |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.89e-10 |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 44400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.31e-05 |\n",
      "|    n_updates        | 11074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 773      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 44800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.58e-10 |\n",
      "|    n_updates        | 11174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000184 |\n",
      "|    n_updates        | 11274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 773      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.19e-07 |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 773      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.8e-10  |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 773      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 46400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 1.31e-05 |\n",
      "|    n_updates        | 11574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 772      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 46800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.31e-10 |\n",
      "|    n_updates        | 11674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 773      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 47200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 11774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 772      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 47600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 5.93e-08 |\n",
      "|    n_updates        | 11874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 772      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 3.35e-10 |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 771      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 48400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.89e-05 |\n",
      "|    n_updates        | 12074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 770      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 48800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 4.18e-09 |\n",
      "|    n_updates        | 12174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 770      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 49200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 12274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 770      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 49600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 2.8e-07  |\n",
      "|    n_updates        | 12374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 770      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 6.08e-10 |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "Model saved to models/dqn_hospital_sb3.zip\n",
      "Mean reward: 1000.00  0.00\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Gym has been unmaintained since\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../env\")  # to read hospital_env.py\n",
    "\n",
    "from hospital_env import HospitalEnv\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ------------------------------\n",
    "# Set seeds for reproducibility\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- Create wrapped environment ---\n",
    "def make_env():\n",
    "    env = HospitalEnv()\n",
    "    env.reset(seed=SEED)   # seed the environment here\n",
    "    env = Monitor(env)      # important for SB3 logging\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "# --- Create DQN agent ---\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",       # Fully connected NN\n",
    "    env,\n",
    "    learning_rate=5e-4,\n",
    "    gamma=0.95,\n",
    "    batch_size=64,\n",
    "    buffer_size=50000,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.1,\n",
    "    exploration_fraction=0.1,   # epsilon decay\n",
    "    target_update_interval=1000,\n",
    "    verbose=1,\n",
    "    seed=SEED                  # seed SB3 agent\n",
    ")\n",
    "\n",
    "# --- Train agent ---\n",
    "model.learn(total_timesteps=50000)\n",
    "\n",
    "# --- Save trained model ---\n",
    "model.save(\"../models/dqn_hospital_sb3\")\n",
    "print(\"Model saved to models/dqn_hospital_sb3.zip\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=50)\n",
    "print(f\"Mean reward: {mean_reward:.2f}  {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfefed8-04e0-4f97-a567-1354a3d6a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl_env)",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
