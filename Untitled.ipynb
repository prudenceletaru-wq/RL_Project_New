{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e987bb-685f-4571-9870-4e49a438195f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque, Counter\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ks_2samp\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Setup logging\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m logging.basicConfig(\n\u001b[32m     12\u001b[39m     filename=\u001b[33m\"\u001b[39m\u001b[33mmonitoring.log\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     level=logging.INFO,\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from collections import deque, Counter\n",
    "import logging\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# -----------------------------------\n",
    "# Setup logging\n",
    "# -----------------------------------\n",
    "logging.basicConfig(\n",
    "    filename=\"monitoring.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# Global buffers for drift detection\n",
    "# -----------------------------------\n",
    "recent_rewards = deque(maxlen=200)\n",
    "recent_actions = deque(maxlen=200)\n",
    "recent_wait_times_red = deque(maxlen=200)\n",
    "recent_wait_times_yellow = deque(maxlen=200)\n",
    "\n",
    "# Historical training distributions (placeholder)\n",
    "# Replace these with real distributions from your training data.\n",
    "train_action_dist = np.array([0.6, 0.4])   # Expected: more red than yellow\n",
    "train_wait_red = np.random.normal(10, 3, 500)\n",
    "train_wait_yellow = np.random.normal(20, 5, 500)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Reward Tracking\n",
    "# ----------------------------------------------------------\n",
    "def track_reward(reward):\n",
    "    recent_rewards.append(reward)\n",
    "    logging.info(f\"Reward logged: {reward}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Action Tracking (Model Drift)\n",
    "# ----------------------------------------------------------\n",
    "def track_action(action):\n",
    "    \"\"\"\n",
    "    Action: 0 = RED, 1 = YELLOW\n",
    "    \"\"\"\n",
    "    recent_actions.append(action)\n",
    "\n",
    "    count = Counter(recent_actions)\n",
    "    total = sum(count.values())\n",
    "    dist = {\n",
    "        \"red\": count.get(0, 0) / total if total else 0,\n",
    "        \"yellow\": count.get(1, 0) / total if total else 0\n",
    "    }\n",
    "\n",
    "    logging.info(f\"Action distribution: {dist}\")\n",
    "\n",
    "    # Drift detection\n",
    "    action_dist_vector = np.array([dist[\"red\"], dist[\"yellow\"]])\n",
    "    drift = np.linalg.norm(action_dist_vector - train_action_dist)\n",
    "\n",
    "    if drift > 0.25:\n",
    "        logging.warning(\"MODEL DRIFT DETECTED: Action distribution deviates significantly.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Wait-Time Drift (Data Drift)\n",
    "# ----------------------------------------------------------\n",
    "def track_wait_time(cat, wait_time):\n",
    "    \"\"\"\n",
    "    cat: \"red\" or \"yellow\"\n",
    "    wait_time: int from environment\n",
    "    \"\"\"\n",
    "    if cat == \"red\":\n",
    "        recent_wait_times_red.append(wait_time)\n",
    "        if len(recent_wait_times_red) > 30:\n",
    "            _check_wait_time_drift(\"red\")\n",
    "    else:\n",
    "        recent_wait_times_yellow.append(wait_time)\n",
    "        if len(recent_wait_times_yellow) > 30:\n",
    "            _check_wait_time_drift(\"yellow\")\n",
    "\n",
    "\n",
    "def _check_wait_time_drift(cat):\n",
    "    \"\"\"\n",
    "    Uses KS-Test to compare new vs training wait times.\n",
    "    \"\"\"\n",
    "    if cat == \"red\":\n",
    "        stat, p = ks_2samp(train_wait_red, list(recent_wait_times_red))\n",
    "    else:\n",
    "        stat, p = ks_2samp(train_wait_yellow, list(recent_wait_times_yellow))\n",
    "\n",
    "    if p < 0.05:\n",
    "        logging.warning(f\"DATA DRIFT DETECTED in {cat.upper()} wait times (p={p:.4f})\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Log every decision\n",
    "# ----------------------------------------------------------\n",
    "def log_decision(obs, action, reward, info):\n",
    "    data = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"action\": int(action),\n",
    "        \"reward\": float(reward),\n",
    "        \"free_doctors\": int(obs[0]),\n",
    "        \"longest_wait_red\": float(obs[1]),\n",
    "        \"longest_wait_yellow\": float(obs[2]),\n",
    "        \"red_queue_len\": int(obs[3]),\n",
    "        \"yellow_queue_len\": int(obs[4]),\n",
    "        \"doctor_busy_times\": [float(obs[5]), float(obs[6]), float(obs[7])],\n",
    "        \"additional_info\": info\n",
    "    }\n",
    "\n",
    "    logging.info(\"Decision: \" + json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6628eb-1511-4cf2-8e3e-4a3950ecaefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque, Counter\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ks_2samp\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Setup logging\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m logging.basicConfig(\n\u001b[32m     12\u001b[39m     filename=\u001b[33m\"\u001b[39m\u001b[33mmonitoring.log\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     level=logging.INFO,\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import logging\n",
    "from collections import deque, Counter\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# -----------------------------------\n",
    "# Setup logging\n",
    "# -----------------------------------\n",
    "logging.basicConfig(\n",
    "    filename=\"monitoring.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# Load training metrics\n",
    "# -----------------------------------\n",
    "with open(\"../training_metrics.json\", \"r\") as f:\n",
    "    training_metrics = json.load(f)\n",
    "\n",
    "train_action_dist = np.array(training_metrics[\"train_action_dist\"])\n",
    "train_wait_red = np.array(training_metrics[\"train_wait_red\"])\n",
    "train_wait_yellow = np.array(training_metrics[\"train_wait_yellow\"])\n",
    "\n",
    "# -----------------------------------\n",
    "# Buffers for live monitoring\n",
    "# -----------------------------------\n",
    "recent_rewards = deque(maxlen=200)\n",
    "recent_actions = deque(maxlen=200)\n",
    "recent_waits_red = deque(maxlen=200)\n",
    "recent_waits_yellow = deque(maxlen=200)\n",
    "\n",
    "# -----------------------------------\n",
    "# Reward tracking\n",
    "# -----------------------------------\n",
    "def track_reward(reward):\n",
    "    recent_rewards.append(reward)\n",
    "    logging.info(f\"Reward logged: {reward}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Action tracking (Model Drift)\n",
    "# -----------------------------------\n",
    "def track_action(action):\n",
    "    \"\"\"\n",
    "    action: 0=Red (urgent), 1=Yellow (non-urgent)\n",
    "    \"\"\"\n",
    "    recent_actions.append(action)\n",
    "    count = Counter(recent_actions)\n",
    "    total = sum(count.values())\n",
    "    dist = {\n",
    "        \"red\": count.get(0, 0)/total if total else 0,\n",
    "        \"yellow\": count.get(1, 0)/total if total else 0\n",
    "    }\n",
    "    logging.info(f\"Current action distribution: {dist}\")\n",
    "\n",
    "    # Model drift detection (Euclidean distance)\n",
    "    action_vector = np.array([dist[\"red\"], dist[\"yellow\"]])\n",
    "    drift = np.linalg.norm(action_vector - train_action_dist)\n",
    "    if drift > 0.25:\n",
    "        logging.warning(\"MODEL DRIFT DETECTED: Action distribution deviates from training behavior!\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Wait-time tracking (Data Drift)\n",
    "# -----------------------------------\n",
    "def track_wait_time(cat, wait_time):\n",
    "    \"\"\"\n",
    "    cat: \"red\" or \"yellow\"\n",
    "    wait_time: float/int\n",
    "    \"\"\"\n",
    "    if cat == \"red\":\n",
    "        recent_waits_red.append(wait_time)\n",
    "        if len(recent_waits_red) > 30:\n",
    "            _check_wait_drift(\"red\")\n",
    "    else:\n",
    "        recent_waits_yellow.append(wait_time)\n",
    "        if len(recent_waits_yellow) > 30:\n",
    "            _check_wait_drift(\"yellow\")\n",
    "\n",
    "def _check_wait_drift(cat):\n",
    "    if cat == \"red\":\n",
    "        stat, p = ks_2samp(train_wait_red, list(recent_waits_red))\n",
    "    else:\n",
    "        stat, p = ks_2samp(train_wait_yellow, list(recent_waits_yellow))\n",
    "    \n",
    "    if p < 0.05:\n",
    "        logging.warning(f\"DATA DRIFT DETECTED in {cat.upper()} wait times (p={p:.4f})\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Log every decision\n",
    "# -----------------------------------\n",
    "def log_decision(obs, action, reward, info={}):\n",
    "    \"\"\"\n",
    "    obs: environment observation array\n",
    "    action: 0=Red, 1=Yellow\n",
    "    reward: float\n",
    "    info: optional dict\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"action\": int(action),\n",
    "        \"reward\": float(reward),\n",
    "        \"free_doctors\": int(obs[0]),\n",
    "        \"longest_wait_red\": float(obs[1]),\n",
    "        \"longest_wait_yellow\": float(obs[2]),\n",
    "        \"red_queue_len\": int(obs[3]),\n",
    "        \"yellow_queue_len\": int(obs[4]),\n",
    "        \"doctor_busy_times\": [float(obs[5]), float(obs[6]), float(obs[7])],\n",
    "        \"additional_info\": info\n",
    "    }\n",
    "    logging.info(\"Decision: \" + json.dumps(data))\n",
    "\n",
    "# -----------------------------------\n",
    "# Example usage (replace with your live environment loop)\n",
    "# -----------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate some sample decisions\n",
    "    for i in range(50):\n",
    "        # Fake observation\n",
    "        obs = np.array([2, 3, 5, 1, 6, 0, 0, 1], dtype=float)\n",
    "        action = np.random.choice([0, 1])\n",
    "        reward = np.random.rand() * 50\n",
    "        track_reward(reward)\n",
    "        track_action(action)\n",
    "        track_wait_time(\"red\" if action==0 else \"yellow\", np.random.rand()*20)\n",
    "        log_decision(obs, action, reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98d1957-073c-46d5-b19e-c34d051c6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\rl_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01521ba9-6938-463f-b454-7540831abc0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ks_2samp\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mscipy works!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "print(\"scipy works!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4c8a21-a786-40f9-9d19-d3c6423d1fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Using cached scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\prudence letaru\\appdata\\roaming\\python\\python312\\site-packages (from scipy) (2.2.6)\n",
      "Using cached scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.16.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "missingno 0.5.2 requires seaborn, which is not installed.\n",
      "mlxtend 0.23.4 requires joblib>=0.13.2, which is not installed.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!C:/rl_env/python.exe -m pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80925b5-e5f2-4294-bbb7-7844a9ef0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy works!\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "print(\"scipy works!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450ea26-40f8-43bf-b0df-7261b5692465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# ---- Loading the Model ----\n",
    "model_path = Path(__file__).resolve().parent.parent / \"models\" / \"dqn_hospital_sb3.zip\"\n",
    "model = DQN.load(str(model_path))\n",
    "\n",
    "# Mapping RL action numbers to readable names\n",
    "action_map = {\n",
    "    0: \"serve_red\",\n",
    "    1: \"serve_yellow\",\n",
    "}\n",
    "\n",
    "# ---- Input Schema ----\n",
    "class Observation(BaseModel):\n",
    "    state: Dict[str, int]  # dictionary with feature names\n",
    "\n",
    "# ---- Prediction Endpoint ----\n",
    "@app.post(\"/predict\")\n",
    "def predict_action(data: Observation):\n",
    "    # Define the correct order your RL model expects\n",
    "    ordered_keys = [\n",
    "        \"free_doctors\",\n",
    "        \"longest_wait_red\",\n",
    "        \"longest_wait_yellow\",\n",
    "        \"red_queue_length\",\n",
    "        \"yellow_queue_length\",\n",
    "        \"doctor1_busy_time\",\n",
    "        \"doctor2_busy_time\",\n",
    "        \"doctor3_busy_time\"\n",
    "    ]\n",
    "\n",
    "    # Convert dictionary to list in correct order\n",
    "    try:\n",
    "        obs = np.array([data.state[key] for key in ordered_keys], dtype=float)\n",
    "    except KeyError as e:\n",
    "        return {\n",
    "            \"error\": f\"Missing required key in state: {e}\"\n",
    "        }\n",
    "\n",
    "    # Checking if all queues are empty\n",
    "    if obs[3] == 0 and obs[4] == 0:\n",
    "        return {\n",
    "            \"action\": None,\n",
    "            \"meaning\": \"No patients in queues\",\n",
    "            \"message\": \"API detected empty queues, no action taken\"\n",
    "        }\n",
    "\n",
    "    # Otherwise, predicting action with RL model\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    readable = action_map[int(action)]\n",
    "    return {\"action\": int(action), \"meaning\": readable}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482106aa-ed13-447f-bdbf-0ef96202eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from collections import deque, Counter\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# -------------------------------\n",
    "# Setup logging\n",
    "# -------------------------------\n",
    "logging.basicConfig(\n",
    "    filename=\"monitoring.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Global buffers for drift detection\n",
    "# -------------------------------\n",
    "recent_rewards = deque(maxlen=200)\n",
    "recent_actions = deque(maxlen=200)\n",
    "recent_wait_red = deque(maxlen=200)\n",
    "recent_wait_yellow = deque(maxlen=200)\n",
    "\n",
    "# -------------------------------\n",
    "# Monitoring functions\n",
    "# -------------------------------\n",
    "def track_reward(reward):\n",
    "    recent_rewards.append(reward)\n",
    "    logging.info(f\"Reward logged: {reward}\")\n",
    "\n",
    "def track_action(action):\n",
    "    recent_actions.append(action)\n",
    "    count = Counter(recent_actions)\n",
    "    total = sum(count.values())\n",
    "    dist = {\n",
    "        \"red\": count.get(0, 0) / total if total else 0,\n",
    "        \"yellow\": count.get(1, 0) / total if total else 0\n",
    "    }\n",
    "    logging.info(f\"Action distribution: {dist}\")\n",
    "\n",
    "    # Model drift detection\n",
    "    action_vector = np.array([dist[\"red\"], dist[\"yellow\"]])\n",
    "    if \"train_action_dist\" in globals():\n",
    "        drift = np.linalg.norm(action_vector - train_action_dist)\n",
    "        if drift > 0.25:\n",
    "            logging.warning(\"MODEL DRIFT DETECTED: Action distribution deviates from training!\")\n",
    "\n",
    "def track_wait_time(cat, wait_time):\n",
    "    if cat == \"red\":\n",
    "        recent_wait_red.append(wait_time)\n",
    "        if len(recent_wait_red) > 30:\n",
    "            _check_wait_time_drift(\"red\")\n",
    "    else:\n",
    "        recent_wait_yellow.append(wait_time)\n",
    "        if len(recent_wait_yellow) > 30:\n",
    "            _check_wait_time_drift(\"yellow\")\n",
    "\n",
    "def _check_wait_time_drift(cat):\n",
    "    if cat == \"red\":\n",
    "        stat, p = ks_2samp(train_wait_red, list(recent_wait_red))\n",
    "    else:\n",
    "        stat, p = ks_2samp(train_wait_yellow, list(recent_wait_yellow))\n",
    "\n",
    "    if p < 0.05:\n",
    "        logging.warning(f\"DATA DRIFT DETECTED in {cat.upper()} wait times (p={p:.4f})\")\n",
    "\n",
    "def log_decision(obs, action, reward, info={}):\n",
    "    # Recursive conversion of NumPy arrays to lists\n",
    "    def convert(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert(v) for k, v in obj.items()}\n",
    "        if isinstance(obj, list):\n",
    "            return [convert(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    obs = convert(obs)\n",
    "    info = convert(info)\n",
    "\n",
    "    data = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"action\": int(action),\n",
    "        \"reward\": float(reward),\n",
    "        \"free_doctors\": int(obs[0]),\n",
    "        \"longest_wait_red\": float(obs[1]),\n",
    "        \"longest_wait_yellow\": float(obs[2]),\n",
    "        \"red_queue_len\": int(obs[3]),\n",
    "        \"yellow_queue_len\": int(obs[4]),\n",
    "        \"doctor_busy_times\": [float(obs[5]), float(obs[6]), float(obs[7])],\n",
    "        \"additional_info\": info\n",
    "    }\n",
    "    logging.info(\"Decision: \" + json.dumps(data))\n",
    "\n",
    "# -------------------------------\n",
    "# Main loop: run actual environment\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = \"C:/Users/Prudence Letaru/Desktop/RL_Project_New\"\n",
    "    sys.path.append(root_dir)\n",
    "    sys.path.append(os.path.join(root_dir, \"env\"))\n",
    "\n",
    "    from hospital_env import HospitalEnv\n",
    "\n",
    "    # Create evaluation environment\n",
    "    def make_env():\n",
    "        env = HospitalEnv()\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "\n",
    "    eval_env = DummyVecEnv([make_env])\n",
    "\n",
    "    # Load trained model\n",
    "    model = DQN.load(os.path.join(root_dir, \"models/dqn_hospital_sb3\"), env=eval_env)\n",
    "\n",
    "    # Load previous training metrics if available\n",
    "    metrics_file = os.path.join(root_dir, \"training_metrics.json\")\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            training_metrics = json.load(f)\n",
    "        train_action_dist = np.array(training_metrics[\"train_action_dist\"])\n",
    "        train_wait_red = np.array(training_metrics[\"train_wait_red\"])\n",
    "        train_wait_yellow = np.array(training_metrics[\"train_wait_yellow\"])\n",
    "    else:\n",
    "        # fallback: uniform distribution\n",
    "        train_action_dist = np.array([0.5, 0.5])\n",
    "        train_wait_red = np.random.normal(10, 3, 500)\n",
    "        train_wait_yellow = np.random.normal(20, 5, 500)\n",
    "\n",
    "    # Evaluation parameters\n",
    "    n_episodes = 40\n",
    "    threshold_times = {\"red\": 15, \"yellow\": 30}\n",
    "\n",
    "    # Metrics storage\n",
    "    rewards_per_episode = []\n",
    "    red_waits, yellow_waits = [], []\n",
    "    queue_lengths = {\"red\": [], \"yellow\": []}\n",
    "    total_actions_red, total_actions_yellow = 0, 0\n",
    "\n",
    "    # -------------------------------\n",
    "    # Run episodes\n",
    "    # -------------------------------\n",
    "    for ep in range(n_episodes):\n",
    "        obs = eval_env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "\n",
    "            if action[0] == 0:\n",
    "                total_actions_red += 1\n",
    "            else:\n",
    "                total_actions_yellow += 1\n",
    "\n",
    "            obs, reward, done, info = eval_env.step(action)\n",
    "            episode_reward += float(reward[0])\n",
    "\n",
    "            env = eval_env.envs[0].unwrapped\n",
    "\n",
    "            # Track metrics\n",
    "            track_reward(float(reward[0]))\n",
    "            track_action(action[0])\n",
    "\n",
    "            # Track wait times only if someone was served\n",
    "            if env.last_served_wait_times[\"red\"] > 0:\n",
    "                red_waits.append(float(env.last_served_wait_times[\"red\"]))\n",
    "                track_wait_time(\"red\", float(env.last_served_wait_times[\"red\"]))\n",
    "            if env.last_served_wait_times[\"yellow\"] > 0:\n",
    "                yellow_waits.append(float(env.last_served_wait_times[\"yellow\"]))\n",
    "                track_wait_time(\"yellow\", float(env.last_served_wait_times[\"yellow\"]))\n",
    "\n",
    "            # Log decision (obs converted inside function)\n",
    "            log_decision(obs[0], action[0], float(reward[0]), info)\n",
    "\n",
    "            # Queue lengths\n",
    "            queue_lengths[\"red\"].append(len(env.red_queue))\n",
    "            queue_lengths[\"yellow\"].append(len(env.yellow_queue))\n",
    "\n",
    "        rewards_per_episode.append(episode_reward)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Compute summary metrics\n",
    "    # -------------------------------\n",
    "    avg_reward = float(np.mean(rewards_per_episode))\n",
    "    avg_wait_red = float(np.mean(red_waits)) if red_waits else 0\n",
    "    avg_wait_yellow = float(np.mean(yellow_waits)) if yellow_waits else 0\n",
    "    pct_red_within = float(100 * sum(w <= threshold_times[\"red\"] for w in red_waits) / len(red_waits)) if red_waits else 0\n",
    "    pct_yellow_within = float(100 * sum(w <= threshold_times[\"yellow\"] for w in yellow_waits) / len(yellow_waits)) if yellow_waits else 0\n",
    "    queue_stats = {cat: {\"avg\": float(np.mean(qs)), \"max\": int(np.max(qs))} for cat, qs in queue_lengths.items()}\n",
    "\n",
    "    # Action distribution\n",
    "    total_actions = total_actions_red + total_actions_yellow\n",
    "    red_pct = float(total_actions_red / total_actions) if total_actions > 0 else 0\n",
    "    yellow_pct = float(total_actions_yellow / total_actions) if total_actions > 0 else 0\n",
    "\n",
    "    # -------------------------------\n",
    "    # Print summary\n",
    "    # -------------------------------\n",
    "    print(\"\\n=== ACTION DISTRIBUTION ===\")\n",
    "    print(f\"Red actions: {total_actions_red} ({red_pct:.3f})\")\n",
    "    print(f\"Yellow actions: {total_actions_yellow} ({yellow_pct:.3f})\")\n",
    "    print(\"\\n=== PERFORMANCE METRICS ===\")\n",
    "    print(f\"Average reward per episode: {avg_reward:.2f}\")\n",
    "    print(f\"Average wait times (Red, Yellow): {avg_wait_red:.2f}, {avg_wait_yellow:.2f}\")\n",
    "    print(f\"Percentage served within thresholds (Red, Yellow): {pct_red_within:.2f}%, {pct_yellow_within:.2f}%\")\n",
    "    for cat, stats in queue_stats.items():\n",
    "        print(f\"{cat.capitalize()}: avg={stats['avg']:.2f}, max={stats['max']}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Save metrics\n",
    "    # -------------------------------\n",
    "    training_metrics = {\n",
    "        \"train_action_dist\": [red_pct, yellow_pct],\n",
    "        \"train_wait_red\": red_waits,\n",
    "        \"train_wait_yellow\": yellow_waits,\n",
    "        \"avg_reward_per_episode\": avg_reward,\n",
    "        \"pct_within_threshold_red\": pct_red_within,\n",
    "        \"pct_within_threshold_yellow\": pct_yellow_within,\n",
    "        \"queue_red_avg\": queue_stats[\"red\"][\"avg\"],\n",
    "        \"queue_red_max\": queue_stats[\"red\"][\"max\"],\n",
    "        \"queue_yellow_avg\": queue_stats[\"yellow\"][\"avg\"],\n",
    "        \"queue_yellow_max\": queue_stats[\"yellow\"][\"max\"]\n",
    "    }\n",
    "\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(training_metrics, f, indent=4)\n",
    "\n",
    "    print(\"\\n[INFO] Monitoring complete. Logs in 'monitoring.log'. Metrics saved in 'training_metrics.json'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl_env)",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
